
---
output: pdf_document
---

```{r pressure2, echo=FALSE, out.width = '210%'}
knitr::include_graphics("CARATULA.PNG")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage
Analizar los datos Quarterly U.S. new plant/equip. expenditures 64 76 billions de la liberia
tsdl de R.

## Análisis descriptivo.
Grafique los datos, describa lo que observe (varianza constante o no
constante, descomposición clásica, tendencia, ciclos estacionales, periodicidad de los ciclos).

Primero carguemos la librería tsdl, ya que los datos necesarios se encuentran en dicha
librería; así como otras necesarias para esta tarea.
```{r,message=FALSE}
library(tsdl);library(ggplot2);library(itsmr);library(forecast);library(TSA);library(lmtest)
library(timeSeries);library(timeSeries);library(astsa);library(dygraphs);
library(tseries);library(forecast);library(nortest);library(dplyr);library(imputeTS)
```

Cargamos la base de datos, nos aseguramos de que es la deseada.
```{r}
Data <- tsdl[[12]]
attributes(Data)
```
Ahora que noa aseguramos de que es la base que queriamos, procedemos a graficar:
```{r}
plot(Data, main = "Quarterly U.S. new plant/equip. expenditures \n 64 76 billions")
```
### Varianza
Al menos de manera gráfica, la intuición nos dice que no hay varianza constante, pero
probémoslo con un test de homocedasticidad:
```{r}
#Los pasamos a series de tiempo
Serie<-ts(data=Data,start=c(1964,01),end=c(1976,4),frequency=4)
tiempo<-seq(1964+0/4, 1976+3/4, by = 1/4)
bptest(Serie~tiempo)
```

Efectivamente, no pasa el test de homocedasticidad. 

Veamos qué pasa si aplicamos la transformación logaritmo:
```{r}
bptest(log(Serie)~tiempo)
plot(log(Serie))
```
Tampoco ayudó, aunque mejoró un poco. Intentemos con la raíz cuadrada
```{r}
bptest(sqrt(Serie)~tiempo)
plot(sqrt(Serie))
```
¡Logramos estabilizarla!

Veamos si es estacionaria.
```{r}
adf.test(sqrt(Serie))
kpss.test(sqrt(Serie))
```
### Tendencia

Podemos observar una tendencia creciente que se presenta de manera lineal (al parecer), 
de manera general a lo largo de la serie

### Ciclos estacionales

Los ciclos están bastante marcados , y tiene sentido puesto que son los datos 
de gastos de una empresa en maquinaria por trimestre, y en ese contexto es 
lógico que se presenten ciclos: Generalmente decae del último trimestre del año anterior 
al primero del año siguiente, para después  crecer en el segundo semestre, en el tercero 
se mantiene casi al mismo nivel que el segundo, pero en el último aumenta; y es un
comportamiento que se repite año con año

### Periodicidad de los ciclos

Como comentamos en el apartado anterior, parece (al menos de manera gráfica) que se
tienen ciclos anuales.

### Descomposición clásica

Descomponeremos la serie por medio de filtros lineales:

#### Estabilización de la varianza

Aplicamos la transformación raíz cuadrada
```{r}
Serie_sq<-sqrt(Serie)
bptest(Serie_sq~tiempo)
```
Podemos asumir varianza constante

#### Periodicidad de ciclos

```{r}
#Veamos la tendencia y los ciclos 
Xt = Serie_sq
p = periodogram(Xt, main="Periodograma", col=4) # Obtenemos el periodograma

names(p)

# Ordenamos de mayor a menor las estimaciones del periodograma.
spec = sort(p$spec, decreasing = TRUE) 
(spec = spec[1:10]) # Nos quedamos con los 8 coeficientes de mayor frecuencia.
i = match(spec, p$spec) # Buscamos sus indices en el periodograma.
d = p$freq # Vemos las frecuencias del periodograma.
d = d[i] # Nos quedamos con las frecuencias que nos interesan.

cbind(spec,d,i)#
d = 1 / d # Obtenemos los parametros para utilizar en promedios moviles.
d = floor(d) #
(d = sort(d))
# Quitamos los periodos mas grandes
d = d[-length(d)] 
d = d[-length(d)]
# Quitamos el más pequeño
d = d[-1]
d #Posibles periodos del ciclo 

#Realizamos la grafica:
col = c("dodgerblue1", "darkorange1", "brown")
plot(Serie_sq, lwd = 3, xlab = "Tiempo", col = "gray0",
     main = "Serie con varianza Homocedastica",
     ylab = "Numero", col.main = "burlywood")
for (i in 1:3) {
  lines(tiempo, stats::filter(Serie_sq, rep(1 / d[i], d[i])), col = col[i], 
        lwd = 3)
}
legend("bottomright", col = col, lty = 2, lwd = 2, bty = "n",
       legend = c(paste("d = ", d[1]), paste("d = ", d[2]),
                  paste("d = ", d[3])), cex = 1)

```
Notemos que $d=2$ parece sobreajustar un poco nuestra gráfica, de hecho, bastante. 
Sin embargo, con $d=4$ podemos obtener un buen suavizamiento sin pagar el costo de 
otros $2$ datos al elegir $d=6$. Veamos el ACF y PACF:

```{r}
tsdisplay(Serie_sq)
```
Y, junto con este último resultado, nos parece ideal concluir que el ciclo es $d=4$

### Tendencia

Ahora, aislemos la tendencia:

```{r}
tendencia = stats::filter(Serie_sq, rep(1/4, 4))
plot(Serie_sq, lwd = 3, xlab = "Tiempo", col = "black",
     main = "Tendencia",
     ylab = "Numero", col.main = "burlywood")
lines(tendencia, col = "gold4", lwd = 4)
legend("bottomright", col = "gold4", lty = 1, lwd = 2, bty = "n",
       legend = "Tendencia", cex = 1)
```

Lo que refuerza lo que creíamos: Tiene tebdebcua creciente casi de manera general.

#### Tendencia

```{r}
# Quitamos la tendencia
# Solo trabajamos con la serie cuya varianza es cte. 

datosSinTendencia = Serie_sq - tendencia # Serie sin tendencia
plot(datosSinTendencia, main="Serie sin tendencia", lwd=2, ylab="", col=14)

# Convertimos datosSinTendencia en objeto TS, dado que hicimos promedios moviles

inicio=start(Serie_sq)
final=end(Serie_sq)

datos.ts4=ts(datosSinTendencia, frequency = 4, start=inicio,end=final) 
which(is.na(datos.ts4)==T)

par(mfrow = c(3,1))
plot(datos.ts4, col = "slateblue4", lwd = 2, ylab = " ", type = "l",
     main = "Serie de tiempo sin tendencia", xlab = "Tiempo")

acf(datos.ts4[2:50])
pacf(datos.ts4[2:50])
par(mfrow = c(1,1))
tsdisplay(datos.ts4, col="purple", lwd=2)
```
Parece que eliminamos la tendencia, ahora tratemos de verificar los ciclos

#Ciclos o parte estacional
 Ahora, estimaremos la parte estacional. Tenemos que d = 4.
Originalmente contábamos con 52 datos, pero ahora tenemos 48 (por los NA), 
entonces $\frac{48}{4}=12$ ciclos.
```{r}
# Creamos un ciclo promedio que estime la parte estacional,
# usando la serie sin tendencia.
d = 4
k = length(datos.ts4) / d # Numero de ciclos de la serie sin tendencia
w = rep(0, 4) 
# Para el resto de los trimestres
for (i in 1:4)
  w[i] = sum(datos.ts4[d * (0:(k-1)) + i], na.rm = TRUE) / k

# Ahora, ajustamos el ciclo obtenido
ciclo  = w - mean(w)
ciclo = ts(rep(ciclo, times = k), start = start(Serie_sq), 
           frequency = frequency(Serie_sq))
par(mfrow = c(1, 1))
plot(ciclo, col =20, lwd = 3, ylab = " ", xlab = "Tiempo",
     main = "Ciclos de la serie")# Es el ciclo de la serie 
# Ciclos anuales
```
Ahora verifiquemos de manera gráfica

```{r}
# Calculamos la parte aleatoria
parte_aleatoria = datos.ts4 - ciclo
plot(parte_aleatoria, main = "Parte aleatoria", 
     col =30, lwd = 3, xlab = "Tiempo", ylab = "") 
plot(Serie_sq)
# Con esto, ya tenemos nuestras series

componentes = tendencia + ciclo+parte_aleatoria
componentes = ts(componentes, start = start(Serie_sq), frequency = 4)
par(mfrow = c(2,1))
plot(Serie_sq, col=28, las=1, main="Serie con varianza constante", lwd=3, xlab="",ylab="")
plot(componentes, col = 18, lwd = 3, las=1, main="Yt=tendencia+ciclos+aleatoria", xlab="",ylab="")

par(mfrow = c(1,1))
plot(Serie_sq,col="darkblue", las=1, lwd=3,main="Serie_ln", ylab="",xlab="")
invisible(lines(componentes, type="l", lwd=3, col="green",lty=6))
legend("bottomright", col = c("darkblue","green"), lty = 1, lwd = 2, bty = "n",
       legend = c("Serie Homocedastica","Yt=T+C+A"), cex = 1)



```

¡Logramos identificar los componentes de la serie!

## Missing data

Suponga que las observaciones de 1971 Qtr1, 1973 Qtr2 y 1973 Qtr3, son
datos faltantes NA, es decir, sustituya estas observaciones por NA.

Use al menos dos métodos de imputación de la paqueteríaa imputeTS. ¿Cuál método es
adecuado para estos datos? (Note que el valor imputado debe aproximarse al valor omitido).

Vamos a poner los datos que se piden, como NA:

```{r}
Original=Serie[29]
Original[2]=Serie[38]
Original[3]=Serie[39]
Serie_2=Serie
Serie_2[29]=NA
Serie_2[38:39]=NA
Serie_2
```

Ahora, veamos método por método:

Un vistazo a la documentación de la paquetería mencionada nos menciona los siguientes 
métodos:


 na\_interpolation:

Missing Value Imputation by Interpolation. Acepta 3 tipos:

 "linear" - for linear interpolation using approx (default choice)

```{r}
Comparaciones=data.frame(Original)
na_interpolation_lineal=na_interpolation(Serie_2,option='linear')[29]-Original[1]
na_interpolation_lineal[2:3]=na_interpolation(Serie_2,option='linear')[38:39]-Original[2:3]
Comparaciones['na_interpolation_lineal']=na_interpolation_lineal
```


 "spline" - for spline interpolation using spline
```{r}
na_interpolation(Serie_2,option='spline')
na_interpolation_spline=na_interpolation(Serie_2,option='spline')[29]-Original[1]
na_interpolation_spline[2:3]=na_interpolation(Serie_2,option='spline')[38:39]-Original[2:3]
Comparaciones['na_interpolation_spline']=na_interpolation_spline
```

 "stine" - for Stineman interpolation using stinterp
```{r}
na_interpolation(Serie_2,option='stine')
na_interpolation_stine=na_interpolation(Serie_2,option='stine')[29]-Original[1]
na_interpolation_stine[2:3]=na_interpolation(Serie_2,option='stine')[38:39]-Original[2:3]
Comparaciones['na_interpolation_stine']=na_interpolation_stine
```



 na\_kalman:

Missing Value Imputation by Kalman Smoothing and State Space Models. Acepta los siguientes modelos:
\begin{enumerate}
 "auto.arima" - For using the state space representation of arima model (using auto.arima) (default choice)
```{r}
na_kalman(Serie_2,model='auto.arima')
na_kalman_auto.arima=na_kalman(Serie_2,model ='auto.arima')[29]-Original[1]
na_kalman_auto.arima[2:3]=na_kalman(Serie_2,model='auto.arima')[38:39]-Original[2:3]
Comparaciones['na_kalman_auto.arima']=na_kalman_auto.arima
```

 "StructTS" - For using a structural model fitted by maximum likelihood (using StructTS)
```{r}
na_kalman(Serie_2,model='StructTS')
na_kalman_StructTS=na_kalman(Serie_2,model='StructTS')[29]-Original[1]
na_kalman_StructTS[2:3]=na_kalman(Serie_2,model='StructTS')[38:39]-Original[2:3]
Comparaciones['na_StructTS']=na_kalman_StructTS
```

 na\_locf:

Missing Value Imputation by Last Observation Carried Forward. Acepta los siguientes métodos:


 "locf" - for Last Observation Carried Forward (default choice)
```{r}
na_locf(Serie_2,option = 'locf')
na_locf=na_locf(Serie_2,option='locf')[29]-Original[1]
na_locf[2:3]=na_locf(Serie_2,option='locf')[38:39]-Original[2:3]
Comparaciones['na_locf']=na_locf
```

 "nocb" - for Next Observation Carried Backward
```{r}
na_locf(Serie_2,option = 'nocb')
na_locf_nocb=na_locf(Serie_2,option='nocb')[29]-Original[1]
na_locf_nocb[2:3]=na_locf(Serie_2,option='nocb')[38:39]-Original[2:3]
Comparaciones['na_locf_nocb']=na_locf_nocb
```



 na\_ma	Missing:

Value Imputation by Weighted Moving Average. Acepta los siguientes métodos:

 "simple" - Simple Moving Average (SMA)
```{r}
na_ma(Serie_2,weighting = 'simple')
na_ma_simple=na_ma(Serie_2,weighting='simple')[29]-Original[1]
na_ma_simple[2:3]=na_ma(Serie_2,weighting='simple')[38:39]-Original[2:3]
Comparaciones['na_ma_simple']=na_ma_simple
```

 "linear" - Linear Weighted Moving Average (LWMA)
```{r}
na_ma(Serie_2,weighting = 'linear')
na_ma_linear=na_interpolation(Serie_2,option='linear')[29]-Original[1]
na_ma_linear[2:3]=na_interpolation(Serie_2,option='linear')[38:39]-Original[2:3]
Comparaciones['na_ma_linear']=na_ma_linear
```
 "exponential" - Exponential Weighted Moving Average (EWMA) (default choice)
```{r}
na_ma(Serie_2,weighting = 'exponential')
na_ma_exponential=na_ma(Serie_2,weighting='exponential')[29]-Original[1]
na_ma_exponential[2:3]=na_ma(Serie_2,weighting='exponential')[38:39]-Original[2:3]
Comparaciones['na_exponential']=na_ma_exponential
```


 na\_mean	Missing:

Value Imputation by Mean Value. Acepta los siguientes métodos:

 "mean" - take the mean for imputation (default choice)
```{r}
na_mean(Serie_2,option = 'mean')
na_mean=na_mean(Serie_2,option='mean')[29]-Original[1]
na_mean[2:3]=na_mean(Serie_2,option='mean')[38:39]-Original[2:3]
Comparaciones['na_mean']=na_mean
```
 "median" - take the median for imputation
```{r}
na_mean(Serie_2,option = 'median')
na_mean_median=na_mean(Serie_2,option='median')[29]-Original[1]
na_mean_median[2:3]=na_mean(Serie_2,option='median')[38:39]-Original[2:3]
Comparaciones['na_mean_median']=na_interpolation_lineal
```
 "mode" - take the mode for imputation
```{r}
na_mean(Serie_2,option = 'mode')
na_mean_mode=na_mean(Serie_2,option='mode')[29]-Original[1]
na_mean_mode[2:3]=na_mean(Serie_2,option='mode')[38:39]-Original[2:3]
Comparaciones['na_mean_mode']=na_mean_mode
```
 "harmonic" - take the harmonic mean
```{r}
na_mean(Serie_2,option = 'harmonic')
na_mean_harmonic=na_mean(Serie_2,option='harmonic')[29]-Original[1]
na_mean_harmonic[2:3]=na_mean(Serie_2,option='harmonic')[38:39]-Original[2:3]
Comparaciones['na_mean_harmonic']=na_mean_harmonic
```
 "geometric" - take the geometric mean
```{r}
na_mean(Serie_2,option = 'geometric')
na_mean_geometric=na_mean(Serie_2,option='geometric')[29]-Original[1]
na_mean_geometric[2:3]=na_mean(Serie_2,option='geometric')[38:39]-Original[2:3]
Comparaciones['na_mean_geometric']=na_mean_geometric
```


 na\_random:

Missing Value Imputation by Random Sample
```{r}
na_random(Serie_2)
na_random=na_random(Serie_2)[29]-Original[1]
na_random[2:3]=na_random(Serie_2)[38:39]-Original[2:3]
Comparaciones['na_random']=na_random
```

 na\_seadec:

Seasonally Decomposed Missing Value Imputation. Admite los siguiente métodos:

 "interpolation" - Imputation by Interpolation (default choice)
```{r}
na_seadec(Serie_2,algorithm = 'interpolation')
na_seadec_interpolation=na_seadec(Serie_2,algorithm='interpolation')[29]-Original[1]
na_seadec_interpolation[2:3]=na_seadec(Serie_2,algorithm='interpolation')[38:39]-Original[2:3]
Comparaciones['na_seadec_interpolation']=na_seadec_interpolation
```

 "locf" - Imputation by Last Observation Carried Forward
```{r}
na_seadec(Serie_2,algorithm = 'locf')
na_seadec_locf=na_seadec(Serie_2,algorithm='locf')[29]-Original[1]
na_seadec_locf[2:3]=na_seadec(Serie_2,algorithm='locf')[38:39]-Original[2:3]
Comparaciones['na_seadec_locf']=na_seadec_locf
```
 "mean" - Imputation by Mean Value
```{r}
na_seadec(Serie_2,algorithm = 'mean')
na_seadec_mean=na_seadec(Serie_2,algorithm = 'mean')[29]-Original[1]
na_seadec_mean[2:3]=na_seadec(Serie_2,algorithm = 'mean')[38:39]-Original[2:3]
Comparaciones['na_seadec_mean']=na_seadec_mean
```
 "random" - Imputation by Random Sample
```{r}
na_seadec(Serie_2,algorithm = 'random')
na_seadec_random=na_seadec(Serie_2,algorithm = 'random')[29]-Original[1]
na_seadec_random[2:3]=na_seadec(Serie_2,algorithm = 'random')[38:39]-Original[2:3]
Comparaciones['na_seadec_random']=na_seadec_random
```
 "kalman" - Imputation by Kalman Smoothing and State Space Models
```{r}
na_seadec(Serie_2,algorithm = 'kalman')
na_seadec_kalman=na_seadec(Serie_2,algorithm = 'kalman')[29]-Original[1]
na_seadec_kalman[2:3]=na_seadec(Serie_2,algorithm = 'kalman')[38:39]-Original[2:3]
Comparaciones['na_seadec_kalman']=na_seadec_kalman
```
 "ma" - Imputation by Weighted Moving Average
```{r}
na_seadec(Serie_2,algorithm = 'ma')
na_seadec_ma=na_seadec(Serie_2,algorithm = 'ma')[29]-Original[1]
na_seadec_ma[2:3]=na_seadec(Serie_2,algorithm = 'ma')[38:39]-Original[2:3]
Comparaciones['na_seadec_ma']=na_seadec_ma
```

 na\_seasplit:

Seasonally Splitted Missing Value Imputation. Admite los siguiente métodos:

 "interpolation" - Imputation by Interpolation (default choice)
```{r}
na_seasplit(Serie_2,algorithm = 'interpolation')
na_seasplit_interpolation=na_seasplit(Serie_2,algorithm = 'interpolation')[29]-Original[1]
na_seasplit_interpolation[2:3]=na_seasplit(Serie_2,algorithm = 'interpolation')[38:39]-Original[2:3]
Comparaciones['na_seadec_interpolation']=na_seasplit_interpolation
```

 "locf" - Imputation by Last Observation Carried Forward
```{r}
na_seasplit(Serie_2,algorithm = 'locf')
na_seadec_locf=na_seasplit(Serie_2,algorithm = 'locf')[29]-Original[1]
na_seadec_locf[2:3]=na_seasplit(Serie_2,algorithm = 'locf')[38:39]-Original[2:3]
Comparaciones['na_seadec_locf']=na_seadec_locf
```
 "mean" - Imputation by Mean Value
```{r}
na_seasplit(Serie_2,algorithm = 'mean')
na_seadec_mean=na_seasplit(Serie_2,algorithm = 'mean')[29]-Original[1]
na_seadec_mean[2:3]=na_seasplit(Serie_2,algorithm = 'mean')[38:39]-Original[2:3]
Comparaciones['na_seadec_mean']=na_seadec_mean
```
 "random" - Imputation by Random Sample
```{r}
na_seasplit(Serie_2,algorithm = 'random')
na_seadec_random=na_seasplit(Serie_2,algorithm = 'random')[29]-Original[1]
na_seadec_random[2:3]=na_seasplit(Serie_2,algorithm = 'random')[38:39]-Original[2:3]
Comparaciones['na_seadec_random']=na_seadec_random
```
 "kalman" - Imputation by Kalman Smoothing and State Space Models
```{r}
na_seasplit(Serie_2,algorithm = 'kalman')
na_seadec_kalman=na_seasplit(Serie_2,algorithm = 'kalman')[29]-Original[1]
na_seadec_kalman[2:3]=na_seasplit(Serie_2,algorithm = 'kalman')[38:39]-Original[2:3]
Comparaciones['na_seadec_kalman']=na_seadec_kalman
```
 "ma" - Imputation by Weighted Moving Average
```{r}
na_seasplit(Serie_2,algorithm = 'ma')
na_seadec_ma=na_seasplit(Serie_2,algorithm = 'ma')[29]-Original[1]
na_seadec_ma[2:3]=na_seasplit(Serie_2,algorithm = 'ma')[38:39]-Original[2:3]
Comparaciones['na_seadec_ma']=na_seadec_ma
```

En el dataframe Comparaciones, lo que hacemos es guardar las diferencias
respecto a la observación original, acorde al método respectivo de ajuste.

Veamos cuál es el que minimiza dicho error:
```{r}
Qr1_1971<-Comparaciones[1,]
Qr2_1973<-Comparaciones[2,]
Qr3_1973<-Comparaciones[3,]

#Para el primer trimiestre de 1971
dif_minima_Qr1_1971<-min(abs(Qr1_1971))
dif_minima_Qr1_1971
metodo_minimiza_Qr1_1971<-which.min(abs(Qr1_1971))
metodo_minimiza_Qr1_1971
#Los 5 mejores
aux_indices1<-(sort.list(abs(Qr1_1971)))[1:5]
i=1
for (indice in aux_indices1){
  print(Qr1_1971[indice])
  i=i+1
}
#Para el segundo trimiestre de 1973
dif_minima_Qr2_1973<-min(abs(Qr2_1973))
dif_minima_Qr2_1973
metodo_minimiza_Qr2_1973<-which.min(abs(Qr2_1973))
metodo_minimiza_Qr2_1973
#Los 5 mejores
aux_indices2<-(sort.list(abs(Qr2_1973)))[1:5]
i=1
for (indice in aux_indices2){
  print(Qr2_1973[indice])
  i=i+1
}
#Para el tercer trimiestre de 1973
dif_minima_Qr3_1973<-min(abs(Qr3_1973))
dif_minima_Qr3_1973
metodo_minimiza_Qr3_1973<-which.min(abs(Qr3_1973))
metodo_minimiza_Qr3_1973
#Los 5 mejores
aux_indices3<-(sort.list(abs(Qr3_1973)))[1:5]
i=1
for (indice in aux_indices3){
  print(Qr2_1973[indice])
  i=i+1
}
```

## Ajuste

Con los datos observados completos, ajuste un modelo ARIMA o SARIMA adecuado.

Obtenga correlogramas, revise si los parámetros son significativos, compruebe los supuestos
(que los residuales sean ruido blanco con distribución normal).
Obtenga dos o más posibles modelos, realice análisis de residuales y calcule medidas de
bondad de ajuste. Haga la comparación para decidir cuál modelo sería el más adecuado.


### ¿Es estacionaria?

En la primera parte vimos que si le aplicamos la transformación raíz cuadrada
a la serie original, pasa la prueba para varianza constnte:
```{r}
bptest(Serie_sq~tiempo)
```

Ahora, las pruebas para estacionariedad:
```{r}
adf.test(Serie_sq)
kpss.test(Serie_sq)
```
No las pasa.

Aplicamos una diferencia

```{r}
plot(diff(Serie_sq), col = "plum", lwd = 3, xlab = "Tiempo", ylab = " ",
     main = "Serie homoscedastica con una diferencia" )
adf.test(diff(Serie_sq))
kpss.test(diff(Serie_sq))
```
Se contradicen. Apliquemos otra diferencia
```{r}
plot(diff(diff(Serie_sq)), col = "plum", lwd = 3, xlab = "Tiempo", ylab = " ",
     main = "Serie homoscedastica con dos diferencias" )
adf.test(diff(diff(Serie_sq)))
kpss.test(diff(diff(Serie_sq)))
```
Pasa las dos pruebas si aplicamos dos diferencias; trabajaremos con esa.

### Correlogramas

```{r}
Serie_est<-diff(diff(Serie_sq))
```

Visualizamos ACF y PACF

```{r}
tsdisplay(Serie_est)
```
```{r}
k=length(Serie_est)
banda<-qnorm(0.95)/(sqrt(k))
auxacf=acf(Serie_est,plot = F)#MA(6)
ACF_superior<-sum(auxacf$acf>banda)
ACF_inferior<-sum(auxacf$acf< -banda)
superan_banda_acf<-ACF_superior+ACF_inferior
superan_banda_acf
pauxacf=pacf(Serie_est,plot = F)#AR(6)
PACF_superior<-sum(pauxacf$acf>banda)
PACF_inferior<-sum(pauxacf$acf< -banda)
superan_banda_pacf<-PACF_superior+PACF_inferior
superan_banda_pacf
```
Parece, a simple vista, que puede que tengamos un ARIMA(3,1,16). Sin embargo, no hemos
considerado la parte de los ciclos aún.

Veamos qué nos dice el ajuste con la función auto.arima:
```{r}
modelo_automatico<-auto.arima(Serie_sq)
modelo_automatico
```

Veamos el ARIMA(3,2,16)...
```{r}
ARIMA<-arima(Serie_sq,order=c(16,2,3))
ARIMA
```

Ahora veamos la gráfica
```{r}
ARIMA_ajuste <- (Serie_sq - residuals(ARIMA))
ts.plot(Serie_sq, lwd=3, main="Comparación ", ylab="", xlab="")
points(ARIMA_ajuste, type = "l", col ="orange", lty = 2, lwd=3)
###Y ahora los residuales
plot(ARIMA$residuals, type="p", col="blue", ylim=c(-0.15,0.15), ylab="", xlab="", main="Datos discrepantes", las=1, lwd=3)
abline(h=3*(var(ARIMA$residuals)), col="purple", lwd=3)
abline(h=-3*(var(ARIMA$residuals)), col="purple",lwd=3)
```
¡Tenemos muchísimos datos discrepantes!
Estamos sobreajustando los datos

Ahora atacaremos el problema con un SARIMA(p,d,q)x(P,D,Q), usando la estrategia
definida en la página 180 de Introduction to Time Series and Forecasting de
Peter Brockwell y Richard Davis.

Por el análisis hecho en la primera parte, sabemos que:
$$s=4$$

Podemos estimar d y D como aquellos que hacen que 
$$Y_t=(1-B)^{d}(1-B^s)^D$$
Sea estacionaria. Probemos con d=0 y D=1
```{r}
plot(diff(Serie_sq,lag=4), col = "plum", lwd = 3, xlab = "Tiempo", ylab = " ",
     main = "Serie homoscedastica con una diferencia de lag=4" )
adf.test(diff(Serie_sq,lag=4))
kpss.test(diff(Serie_sq,lag=4))
```

¡Las pasa! Entonces:
$$d=0,D=1$$

Trabajaremos con esta serie. Veamos su ACF y PACF

```{r}
Serie_est<-diff(Serie_sq,lag=4)
tsdisplay(Serie_est)
```
¡Se ve mucho mejor que el anterior!

¿Cómo elegimos P y Q?
La metodología seguida nos dice que veamos los lags que son múltiplos del ciclo
(de s=4), y ver aquellos que se ajustan a un ARMA(P,Q). Es decir, en los lags
ks $s=4, k\in\mathbb{N}\setminus\{0\}$

¿Cómo elegimos p y q? Debemos fijarnos en aquellos lags entre 1 y s-1, es decir:
Nos fijaremos en los lags $1,2,3$ y los ajustaremos a un ARMA(p,q)

Veamos el ACF
```{r}
k=length(Serie_est)
banda<-qnorm(0.95)/(sqrt(k))
auxacf=acf(Serie_est,plot = F)#MA(6)
ACF_superior<-sum(auxacf$acf>banda)
ACF_inferior<-sum(auxacf$acf< -banda)
superan_banda_acf<-ACF_superior+ACF_inferior
superan_banda_acf
#Los que superan las bandas del acf son:
which(abs(auxacf$acf) > banda)
```
Por lo que:
$$q=2,Q=1$$

Para el PACF:
```{r}
pauxacf=pacf(Serie_est,plot = F)
PACF_superior<-sum(pauxacf$acf>banda)
PACF_inferior<-sum(pauxacf$acf< -banda)
superan_banda_pacf<-PACF_superior+PACF_inferior
superan_banda_pacf
#Los que superan las bandas del pacf son:
which(abs(pauxacf$acf) > banda)
```
Por lo que:
$$p=2, P=0$$
Entonces tenemos un modelo 

$$SARIMA(2,0,2)\times(0,1,1)_{\left[4\right]}$$
Ajustémoslo:

```{r}
SARIMA<-arima(Serie_est,order=c(2,0,1),seasonal=list(order=c(0,1,1),period=4), include.mean=F) 
SARIMA
```

```{r}
SARIMA_ajuste <- Serie_sq - residuals(SARIMA)
ts.plot(Serie_sq, lwd=3, main="Comparación ", ylab="", xlab="")
points(SARIMA_ajuste, type = "l", col ="orange", lty = 2, lwd=3)
###Y ahora los residuales
plot(SARIMA$residuals, type="p", col="blue", ylim=c(-.15,.15), ylab="", xlab="", main="Datos discrepantes", las=1, lwd=3)
abline(h=3*(var(SARIMA$residuals)), col="purple", lwd=2)
abline(h=-3*(var(SARIMA$residuals)), col="purple",lwd=2)
```
Parece que es un buen modelo, al menos en el sentido de que ajusta bien.

Comparemos con el que ajusta R:

```{r}
AUTOMATICO_ajuste <- Serie_sq - residuals(modelo_automatico)
ts.plot(Serie_sq, lwd=3, main="Comparación ", ylab="", xlab="")
points(AUTOMATICO_ajuste, type = "l", col ="orange", lty = 2, lwd=3)
###Y ahora los residuales
plot(modelo_automatico$residuals, type="p", col="blue", ylim=c(-.15,.15), ylab="", xlab="", main="Datos discrepantes", las=1, lwd=3)
abline(h=3*(var(modelo_automatico$residuals)), col="purple", lwd=2)
abline(h=-3*(var(modelo_automatico$residuals)), col="purple",lwd=2)
```
Al menos de manera visual, parece que el modelo que nosotros propusimos le 
ajusta mejor. No quitaremos ningún dato debido a que hay varios datos
discrepantes, pero por muy poco. Sin embargo, el ajuste automático llega a 
sobreestimar un poco las observaciones. Analizemos estos dos modelos:

Por el AIC y BIC
```{r}
AIC<-c(SARIMA$aic,ARIMA$aic,modelo_automatico$aic)
BIC<-c(SARIMA$bic,ARIMA$bic,modelo_automatico$bic)
loglik<-c(SARIMA$loglik,ARIMA$loglik,modelo_automatico$loglik)
Comparar<-data.frame('AIC'=AIC,'BIC'=BIC,'Loglik'=loglik,row.names = c('SARIMA','ARIMA','Automatico'))
Comparar
```
Comparemos los errores:
```{r}
comparar_=cbind("ARIMA",ARIMA$aic,BIC(ARIMA), mean(ARIMA$residuals),
                mean(abs(ARIMA$residuals)),sqrt(mean((ARIMA$residuals)^2)),
                12)

comparar_2=cbind("SARIMA",SARIMA$aic,BIC(SARIMA), mean(SARIMA$residuals),
                 mean(abs(SARIMA$residuals)),sqrt(mean((SARIMA$residuals)^2)),
                 8)

comparar_3=cbind("SARIMA con drift",modelo_automatico$aic,BIC(modelo_automatico), mean(modelo_automatico$residuals),
                 mean(abs(modelo_automatico$residuals)),sqrt(mean((modelo_automatico$residuals)^2)),
                 3)
nombres=cbind("AJUSTE", "AIC", "BIC","ME","MAE", "RMSE","#Paramatros")

resultados<-rbind(comparar_,comparar_2,comparar_3)
resultados<-as.table(resultados)
colnames(resultados)=c("AJUSTE", "AIC", "BIC","ME","MAE", "RMSE","#Parametros")
rownames(resultados)=c("","", "")

(resultados)
```

Hagamos la comprobación de supuestos:

### Normalidad

#### ARIMA
```{r}
#ARIMA
qqnorm(ARIMA$residuals)
qqline(ARIMA$residuals, col="red", lwd=2)
#Prueba Anderson-Darling
ad.test(ARIMA$residuals)
#Prueba de Shapiro
shapiro.test(ARIMA$residuals)
#Jarque-Bera Test
jarque.bera.test(ARIMA$residuals)
```

#### SARIMA
```{r}
#SARIMA
qqnorm(SARIMA$residuals)
qqline(SARIMA$residuals, col="red", lwd=2)
#Prueba Anderson-Darling
ad.test(SARIMA$residuals)
#Prueba de Shapiro
shapiro.test(SARIMA$residuals)
#Jarque-Bera Test. tseries
jarque.bera.test(SARIMA$residuals)
```

#### SARIMA con drift
```{r}
#SARIMA con drift
qqnorm(modelo_automatico$residuals)
qqline(modelo_automatico$residuals, col="red", lwd=2)
#Prueba Anderson-Darling
ad.test(modelo_automatico$residuals)
#Prueba de Shapiro
shapiro.test(modelo_automatico$residuals)
#Jarque-Bera Test. tseries
jarque.bera.test(modelo_automatico$residuals)
```

Parece que el SARIMA tiene p-values más grandes y se ajusta mejor al qq-plot.

### Varianza constante

#### ARIMA
```{r}
#ARIMA
Y <- as.numeric(ARIMA$residuals)
X <- 1:length(ARIMA$residuals)
bptest(Y ~ X)
```

#### SARIMA
```{r}
#SARIMA
Y <- as.numeric(SARIMA$residuals)
X <- 1:length(SARIMA$residuals)
bptest(Y ~ X)
```

#### SARIMA con drift
```{r}
#SARIMA con drift
Y <- as.numeric(modelo_automatico$residuals)
X <- 1:length(modelo_automatico$residuals)
bptest(Y ~ X)
```

### Media cero 

#### ARIMA
```{r}
t.test(ARIMA$residuals,mu=0)
```
#### SARIMA
```{r}
t.test(SARIMA$residuals,mu=0)
```
#### SARIMA con drift
```{r}
t.test(modelo_automatico$residuals,mu=0)
```
### Residuales no correlacionados

#### ARIMA
```{r}
checkresiduals(ARIMA$residuals)
ggtsdisplay(ARIMA$residuals,main="Residuales")
#Notamos que se "sale" en muchos lags por lo que:
#Box-Pierce test contrasta
# Ho: Independencia vs. H1: Dependencia
Box.test(ARIMA$residuals, lag =10) #
#Por lo que no están relacionados de manera conjunta

#De manera conjunta, con la prueba de Ljung y Box
#H0:No estan correlacionados de manera conjunta 
# vs 
#H1:Estan correlacionados de manera conjunta
tsdiag(ARIMA)
```
#### SARIMA
```{r}
checkresiduals(SARIMA$residuals)
ggtsdisplay(SARIMA$residuals,main="Residuales")
#Notamos que se "sale" en muchos lags por lo que:
#Box-Pierce test contrasta
# Ho: Independencia vs. H1: Dependencia
Box.test(SARIMA$residuals, lag =10) #
#Por lo que:

#De manera conjunta, con la prueba de Ljung y Box
#H0:No estan correlacionados de manera conjunta 
# vs 
#H1:Estan correlacionados de manera conjunta
tsdiag(SARIMA)
```
#### SARIMA con drift
```{r}
checkresiduals(modelo_automatico$residuals)
ggtsdisplay(modelo_automatico$residuals,main="Residuales")
#Notamos que se "sale" en muchos lags por lo que:
#Box-Pierce test contrasta
# Ho: Independencia vs. H1: Dependencia
Box.test(modelo_automatico$residuals, lag =10) #
#Por lo que:

#De manera conjunta, con la prueba de Ljung y Box
#H0:No estan correlacionados de manera conjunta 
# vs 
#H1:Estan correlacionados de manera conjunta
tsdiag(modelo_automatico)
```
## Forecasting 

Con el modelo estimado, pronostique $n_{new}=$ 8 (2 años) valores futuros (obtenga
intervalos de predicción).