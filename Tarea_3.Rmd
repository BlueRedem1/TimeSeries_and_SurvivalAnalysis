
---
output: pdf_document
---

```{r pressure2, echo=FALSE, out.width = '210%'}
knitr::include_graphics("CARATULA.PNG")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage
Analizar los datos Quarterly U.S. new plant/equip. expenditures 64 76 billions de la liberia
tsdl de R.

# 1. Análisis descriptivo.
Grafique los datos, describa lo que observe (varianza constante o no
constante, descomposición clásica, tendencia, ciclos estacionales, periodicidad de los ciclos).

Primero carguemos la librería tsdl, ya que los datos necesarios se encuentran en dicha
librería; así como otras necesarias para esta tarea.
```{r,message=FALSE}
library(tsdl);library(ggplot2);library(itsmr);library(forecast);library(TSA);library(lmtest)
library(timeSeries);library(timeSeries);library(astsa);library(dygraphs);
library(tseries);library(forecast);library(nortest);library(dplyr);library(imputeTS)
```

Cargamos la base de datos, nos aseguramos de que es la deseada.
```{r}
Data <- tsdl[[12]]
attributes(Data)
```
Ahora que noa aseguramos de que es la base que queriamos, procedemos a graficar:
```{r}
plot(Data, main = "Quarterly U.S. new plant/equip. expenditures \n 64 76 billions")
```
## Varianza
Al menos de manera gráfica, la intuición nos dice que no hay varianza constante, pero
probémoslo con un test de homocedasticidad:
```{r}
#Los pasamos a series de tiempo
Serie<-ts(data=Data,start=c(1964,01),end=c(1976,4),frequency=4)
tiempo<-seq(1964+0/4, 1976+3/4, by = 1/4)
bptest(Serie~tiempo)
```

Efectivamente, no pasa el test de homocedasticidad. 

Veamos qué pasa si aplicamos la transformación logaritmo:
```{r}
bptest(log(Serie)~tiempo)
plot(log(Serie))
```
Tampoco ayudó, aunque mejoró un poco. Intentemos con la raíz cuadrada
```{r}
bptest(sqrt(Serie)~tiempo)
plot(sqrt(Serie))
```
¡Logramos estabilizarla!

Veamos si es estacionaria.
```{r}
adf.test(sqrt(Serie))
kpss.test(sqrt(Serie))
```
## Tendencia

Podemos observar una tendencia creciente que se presenta de manera lineal (al parecer), 
de manera general a lo largo de la serie

## Ciclos estacionales

Los ciclos están bastante marcados , y tiene sentido puesto que son los datos 
de gastos de una empresa en maquinaria por trimestre, y en ese contexto es 
lógico que se presenten ciclos: Generalmente decae del último trimestre del año anterior 
al primero del año siguiente, para después  crecer en el segundo semestre, en el tercero 
se mantiene casi al mismo nivel que el segundo, pero en el último aumenta; y es un
comportamiento que se repite año con año

## Periodicidad de los ciclos

Como comentamos en el apartado anterior, parece (al menos de manera gráfica) que se
tienen ciclos anuales.

## Descomposición clásica

Descomponeremos la serie por medio de filtros lineales:

### Estabilización de la varianza

Aplicamos la transformación raíz cuadrada
```{r}
Serie_sq<-sqrt(Serie)
bptest(Serie_sq~tiempo)
```
Podemos asumir varianza constante

### Periodicidad de ciclos

```{r}
#Veamos la tendencia y los ciclos 
Xt = Serie_sq
p = periodogram(Xt, main="Periodograma", col=4) # Obtenemos el periodograma

names(p)

# Ordenamos de mayor a menor las estimaciones del periodograma.
spec = sort(p$spec, decreasing = TRUE) 
(spec = spec[1:10]) # Nos quedamos con los 8 coeficientes de mayor frecuencia.
i = match(spec, p$spec) # Buscamos sus indices en el periodograma.
d = p$freq # Vemos las frecuencias del periodograma.
d = d[i] # Nos quedamos con las frecuencias que nos interesan.

cbind(spec,d,i)#
d = 1 / d # Obtenemos los parametros para utilizar en promedios moviles.
d = floor(d) #
(d = sort(d))
# Quitamos los periodos mas grandes
d = d[-length(d)] 
d = d[-length(d)]
# Quitamos el más pequeño
d = d[-1]
d #Posibles periodos del ciclo 

#Realizamos la grafica:
col = c("cyan1", "aquamarine4", "deepskyblue1")
plot(Serie_sq, lwd = 3, xlab = "Tiempo", col = "hotpink4",
     main = "Serie con varianza Homocedastica",
     ylab = "Numero", col.main = "burlywood")
for (i in 1:3) {
  lines(tiempo, stats::filter(Serie_sq, rep(1 / d[i], d[i])), col = col[i], 
        lwd = 3)
}
legend("bottomright", col = col, lty = 2, lwd = 2, bty = "n",
       legend = c(paste("d = ", d[1]), paste("d = ", d[2]),
                  paste("d = ", d[3])), cex = 1)

```
Notemos que $d=2$ parece sobreajustar un poco nuestra gráfica, de hecho, bastante. 
Sin embargo, con $d=4$ podemos obtener un buen suavizamiento sin pagar el costo de 
otros $2$ datos al elegir $d=6$. Veamos el ACF y PACF:

```{r}
tsdisplay(Serie_sq)
```
Y, junto con este último resultado, nos parece ideal concluir que el ciclo es $d=4$

## Tendencia

Ahora, aislemos la tendencia:

```{r}
tendencia = stats::filter(Serie_sq, rep(1/4, 4))
plot(Serie_sq, lwd = 3, xlab = "Tiempo", col = "firebrick2",
     main = "Tendencia",
     ylab = "Numero", col.main = "burlywood")
lines(tendencia, col = "darkorange1", lwd = 4)
legend("bottomright", col = "darkorange1", lty = 1, lwd = 2, bty = "n",
       legend = "Tendencia", cex = 1)
```

Lo que refuerza lo que creíamos: Tiene tebdebcua creciente casi de manera general.


```{r}
# Quitamos la tendencia
# Solo trabajamos con la serie cuya varianza es cte. 

datosSinTendencia = Serie_sq - tendencia # Serie sin tendencia
plot(datosSinTendencia, main="Serie sin tendencia", lwd=2, ylab="", col=14)

# Convertimos datosSinTendencia en objeto TS, dado que hicimos promedios moviles

inicio=start(Serie_sq)
final=end(Serie_sq)

datos.ts4=ts(datosSinTendencia, frequency = 4, start=inicio,end=final) 
which(is.na(datos.ts4)==T)

par(mfrow = c(3,1))
plot(datos.ts4, col = "gold1", lwd = 2, ylab = " ", type = "l",
     main = "Serie de tiempo sin tendencia", xlab = "Tiempo")

acf(datos.ts4[2:50])
pacf(datos.ts4[2:50])
par(mfrow = c(1,1))
tsdisplay(datos.ts4, col="darkorchid1", lwd=2)
```
Parece que eliminamos la tendencia, ahora tratemos de verificar los ciclos

## Ciclos o parte estacional
 Ahora, estimaremos la parte estacional. Tenemos que d = 4.
Originalmente contábamos con 52 datos, pero ahora tenemos 48 (por los NA), 
entonces $\frac{48}{4}=12$ ciclos.
```{r}
# Creamos un ciclo promedio que estime la parte estacional,
# usando la serie sin tendencia.
d = 4
k = length(datos.ts4) / d # Numero de ciclos de la serie sin tendencia
w = rep(0, 4) 
# Para el resto de los trimestres
for (i in 1:4)
  w[i] = sum(datos.ts4[d * (0:(k-1)) + i], na.rm = TRUE) / k

# Ahora, ajustamos el ciclo obtenido
ciclo  = w - mean(w)
ciclo = ts(rep(ciclo, times = k), start = start(Serie_sq), 
           frequency = frequency(Serie_sq))
par(mfrow = c(1, 1))
plot(ciclo, col =20, lwd = 3, ylab = " ", xlab = "Tiempo",
     main = "Ciclos de la serie")# Es el ciclo de la serie 
# Ciclos anuales
```
Ahora verifiquemos de manera gráfica

```{r}
# Calculamos la parte aleatoria
parte_aleatoria = datos.ts4 - ciclo
plot(parte_aleatoria, main = "Parte aleatoria", 
     col =30, lwd = 3, xlab = "Tiempo", ylab = "") 
plot(Serie_sq)
# Con esto, ya tenemos nuestras series

componentes = tendencia + ciclo+parte_aleatoria
componentes = ts(componentes, start = start(Serie_sq), frequency = 4)
par(mfrow = c(2,1))
plot(Serie_sq, col=28, las=1, main="Serie con varianza constante", lwd=3, xlab="",ylab="")
plot(componentes, col = 18, lwd = 3, las=1, main="Yt=tendencia+ciclos+aleatoria", xlab="",ylab="")

par(mfrow = c(1,1))
plot(Serie_sq,col="deeppink", las=1, lwd=3,main="Serie_ln", ylab="",xlab="")
invisible(lines(componentes, type="l", lwd=3, col="deepskyblue",lty=6))
legend("bottomright", col = c("deeppink","deepskyblue"), lty = 1, lwd = 2, bty = "n",
       legend = c("Serie Homocedastica","Yt=T+C+A"), cex = 1)



```

¡Logramos identificar los componentes de la serie!

# 2. Missing data

Suponga que las observaciones de 1971 Qtr1, 1973 Qtr2 y 1973 Qtr3, son
datos faltantes NA, es decir, sustituya estas observaciones por NA.

Use al menos dos métodos de imputación de la paqueteríaa imputeTS. ¿Cuál método es
adecuado para estos datos? (Note que el valor imputado debe aproximarse al valor omitido).

Vamos a poner los datos que se piden, como NA:

```{r}
Original=Serie[29]
Original[2]=Serie[38]
Original[3]=Serie[39]
Serie_2=Serie
Serie_2[29]=NA
Serie_2[38:39]=NA
Serie_2
```

Ahora, veamos método por método:

Un vistazo a la documentación de la paquetería mencionada nos menciona los siguientes 
métodos:


 na\_interpolation:

Missing Value Imputation by Interpolation. Acepta 3 tipos:

 "linear" - for linear interpolation using approx (default choice)

```{r}
Comparaciones=data.frame(Original)
na_interpolation(Serie_2,option='linear')[29] #Primer dato imputado
na_interpolation(Serie_2,option='linear')[38] #Segundo dato imputado
na_interpolation(Serie_2,option='linear')[39] #Tercer dato imputado
na_interpolation_lineal=na_interpolation(Serie_2,option='linear')[29]-Original[1]
na_interpolation_lineal[2:3]=na_interpolation(Serie_2,option='linear')[38:39]-Original[2:3]
Comparaciones['na_interpolation_lineal']=na_interpolation_lineal
```


 "spline" - for spline interpolation using spline
```{r}
na_interpolation(Serie_2,option='spline')[29] #Primer dato imputado
na_interpolation(Serie_2,option='spline')[38] #Segundo dato imputado
na_interpolation(Serie_2,option='spline')[39] #Tercer dato imputado
na_interpolation_spline=na_interpolation(Serie_2,option='spline')[29]-Original[1]
na_interpolation_spline[2:3]=na_interpolation(Serie_2,option='spline')[38:39]-Original[2:3]
Comparaciones['na_interpolation_spline']=na_interpolation_spline
```

 "stine" - for Stineman interpolation using stinterp
```{r}
na_interpolation(Serie_2,option='stine')[29] #Primer dato imputado
na_interpolation(Serie_2,option='stine')[38] #Segundo dato imputado
na_interpolation(Serie_2,option='stine')[39] #Tercer dato imputado
na_interpolation_stine=na_interpolation(Serie_2,option='stine')[29]-Original[1]
na_interpolation_stine[2:3]=na_interpolation(Serie_2,option='stine')[38:39]-Original[2:3]
Comparaciones['na_interpolation_stine']=na_interpolation_stine
```



 na\_kalman:

Missing Value Imputation by Kalman Smoothing and State Space Models. Acepta los siguientes modelos:
\begin{enumerate}
 "auto.arima" - For using the state space representation of arima model (using auto.arima) (default choice)
```{r}
na_kalman(Serie_2,model='auto.arima')[29] #Primer dato imputado
na_kalman(Serie_2,model='auto.arima')[38] #Segundo dato imputado
na_kalman(Serie_2,model='auto.arima')[39] #Tercer dato imputado
na_kalman_auto.arima=na_kalman(Serie_2,model ='auto.arima')[29]-Original[1]
na_kalman_auto.arima[2:3]=na_kalman(Serie_2,model='auto.arima')[38:39]-Original[2:3]
Comparaciones['na_kalman_auto.arima']=na_kalman_auto.arima
```

 "StructTS" - For using a structural model fitted by maximum likelihood (using StructTS)
```{r}
na_kalman(Serie_2,model='StructTS')[29] #Primer dato imputado
na_kalman(Serie_2,model='StructTS')[38] #Segundo dato imputado
na_kalman(Serie_2,model='StructTS')[39] #Tercer dato imputado
na_kalman_StructTS=na_kalman(Serie_2,model='StructTS')[29]-Original[1]
na_kalman_StructTS[2:3]=na_kalman(Serie_2,model='StructTS')[38:39]-Original[2:3]
Comparaciones['na_StructTS']=na_kalman_StructTS
```

 na\_locf:

Missing Value Imputation by Last Observation Carried Forward. Acepta los siguientes métodos:


 "locf" - for Last Observation Carried Forward (default choice)
```{r}
na_locf(Serie_2,option = 'locf')[29] #Primer dato imputado
na_locf(Serie_2,option = 'locf')[38] #Segundo dato imputado
na_locf(Serie_2,option = 'locf')[39] #Tercer dato imputado
na_locf=na_locf(Serie_2,option='locf')[29]-Original[1]
na_locf[2:3]=na_locf(Serie_2,option='locf')[38:39]-Original[2:3]
Comparaciones['na_locf']=na_locf
```

 "nocb" - for Next Observation Carried Backward
```{r}
na_locf(Serie_2,option = 'nocb')[29] #Primer dato imputado
na_locf(Serie_2,option = 'nocb')[38] #Segundo dato imputado
na_locf(Serie_2,option = 'nocb')[39] #Tercer dato imputado
na_locf_nocb=na_locf(Serie_2,option='nocb')[29]-Original[1]
na_locf_nocb[2:3]=na_locf(Serie_2,option='nocb')[38:39]-Original[2:3]
Comparaciones['na_locf_nocb']=na_locf_nocb
```



 na\_ma	Missing:

Value Imputation by Weighted Moving Average. Acepta los siguientes métodos:

 "simple" - Simple Moving Average (SMA)
```{r}
na_ma(Serie_2,weighting = 'simple')[29] #Primer dato imputado
na_ma(Serie_2,weighting = 'simple')[38] #Segundo dato imputado
na_ma(Serie_2,weighting = 'simple')[39] #Tercer dato imputado
na_ma_simple=na_ma(Serie_2,weighting='simple')[29]-Original[1]
na_ma_simple[2:3]=na_ma(Serie_2,weighting='simple')[38:39]-Original[2:3]
Comparaciones['na_ma_simple']=na_ma_simple
```

 "linear" - Linear Weighted Moving Average (LWMA)
```{r}
na_ma(Serie_2,weighting = 'linear')[29] #Primer dato imputado
na_ma(Serie_2,weighting = 'linear')[38] #Segundo dato imputado
na_ma(Serie_2,weighting = 'linear')[39] #Tercer dato imputado
na_ma_linear=na_interpolation(Serie_2,option='linear')[29]-Original[1]
na_ma_linear[2:3]=na_interpolation(Serie_2,option='linear')[38:39]-Original[2:3]
Comparaciones['na_ma_linear']=na_ma_linear
```
 "exponential" - Exponential Weighted Moving Average (EWMA) (default choice)
```{r} 
na_ma(Serie_2,weighting = 'exponential')[29] #Primer Dato imputado
na_ma(Serie_2,weighting = 'exponential')[38] #Segundo dato imputado
na_ma(Serie_2,weighting = 'exponential')[39] #Tercer dato imputado
na_ma_exponential=na_ma(Serie_2,weighting='exponential')[29]-Original[1]
na_ma_exponential[2:3]=na_ma(Serie_2,weighting='exponential')[38:39]-Original[2:3]
Comparaciones['na_exponential']=na_ma_exponential
```


 na\_mean	Missing:

Value Imputation by Mean Value. Acepta los siguientes métodos:

 "mean" - take the mean for imputation (default choice)
```{r}
na_mean(Serie_2,option = 'mean')[29] #Primer dato imputado
na_mean(Serie_2,option = 'mean')[38] #Segundo dato imputado
na_mean(Serie_2,option = 'mean')[39] #Tercer dato imputado
na_mean=na_mean(Serie_2,option='mean')[29]-Original[1]
na_mean[2:3]=na_mean(Serie_2,option='mean')[38:39]-Original[2:3]
Comparaciones['na_mean']=na_mean
```
 "median" - take the median for imputation
```{r}
na_mean(Serie_2,option = 'median')[29] #Primer dato imputado
na_mean(Serie_2,option = 'median')[38] #Segundo dato imputado
na_mean(Serie_2,option = 'median')[39] #Tercer dato imputado
na_mean_median=na_mean(Serie_2,option='median')[29]-Original[1]
na_mean_median[2:3]=na_mean(Serie_2,option='median')[38:39]-Original[2:3]
Comparaciones['na_mean_median']=na_interpolation_lineal
```
 "mode" - take the mode for imputation
```{r}
na_mean(Serie_2,option = 'mode')[29] #Primer dato imputado
na_mean(Serie_2,option = 'mode')[38] #Segundo dato imputado
na_mean(Serie_2,option = 'mode')[39] #Tercer dato imputado
na_mean_mode=na_mean(Serie_2,option='mode')[29]-Original[1]
na_mean_mode[2:3]=na_mean(Serie_2,option='mode')[38:39]-Original[2:3]
Comparaciones['na_mean_mode']=na_mean_mode
```
 "harmonic" - take the harmonic mean
```{r}
na_mean(Serie_2,option = 'harmonic')[29] #Primer dato imputado
na_mean(Serie_2,option = 'harmonic')[38] #Segundo dato imputado
na_mean(Serie_2,option = 'harmonic')[39] #Tercer dato imputado
na_mean_harmonic=na_mean(Serie_2,option='harmonic')[29]-Original[1]
na_mean_harmonic[2:3]=na_mean(Serie_2,option='harmonic')[38:39]-Original[2:3]
Comparaciones['na_mean_harmonic']=na_mean_harmonic
```
 "geometric" - take the geometric mean
```{r}
na_mean(Serie_2,option = 'geometric')[29] #Primer dato imputado
na_mean(Serie_2,option = 'geometric')[38] #Segundo dato imputado
na_mean(Serie_2,option = 'geometric')[39] #Tercer dato imputado
na_mean_geometric=na_mean(Serie_2,option='geometric')[29]-Original[1]
na_mean_geometric[2:3]=na_mean(Serie_2,option='geometric')[38:39]-Original[2:3]
Comparaciones['na_mean_geometric']=na_mean_geometric
```


 na\_random:

Missing Value Imputation by Random Sample
```{r}
na_random(Serie_2)[29] #Primer dato imputado
na_random(Serie_2)[38] #Segundo dato imputado
na_random(Serie_2)[39] #Tercer dato imputado
na_random=na_random(Serie_2)[29]-Original[1]
na_random[2:3]=na_random(Serie_2)[38:39]-Original[2:3]
Comparaciones['na_random']=na_random
```

 na\_seadec:

Seasonally Decomposed Missing Value Imputation. Admite los siguiente métodos:

 "interpolation" - Imputation by Interpolation (default choice)
```{r}
na_seadec(Serie_2,algorithm = 'interpolation')[29] #Primer dato imputado
na_seadec(Serie_2,algorithm = 'interpolation')[38] #Segundo dato imputado
na_seadec(Serie_2,algorithm = 'interpolation')[39] #Tercer dato imputado
na_seadec_interpolation=na_seadec(Serie_2,algorithm='interpolation')[29]-Original[1]
na_seadec_interpolation[2:3]=na_seadec(Serie_2,algorithm='interpolation')[38:39]-Original[2:3]
Comparaciones['na_seadec_interpolation']=na_seadec_interpolation
```

 "locf" - Imputation by Last Observation Carried Forward
```{r}
na_seadec(Serie_2,algorithm = 'locf')[29] #Primer dato imputado
na_seadec(Serie_2,algorithm = 'locf')[38] #Segundo dato imputado
na_seadec(Serie_2,algorithm = 'locf')[39] #Tercer dato imputado
na_seadec_locf=na_seadec(Serie_2,algorithm='locf')[29]-Original[1]
na_seadec_locf[2:3]=na_seadec(Serie_2,algorithm='locf')[38:39]-Original[2:3]
Comparaciones['na_seadec_locf']=na_seadec_locf
```
 "mean" - Imputation by Mean Value
```{r}
na_seadec(Serie_2,algorithm = 'mean')[29] #Primer dato imputado
na_seadec(Serie_2,algorithm = 'mean')[38] #Segundo dato imputado
na_seadec(Serie_2,algorithm = 'mean')[39] #Tercer dato imputado
na_seadec_mean=na_seadec(Serie_2,algorithm = 'mean')[29]-Original[1]
na_seadec_mean[2:3]=na_seadec(Serie_2,algorithm = 'mean')[38:39]-Original[2:3]
Comparaciones['na_seadec_mean']=na_seadec_mean
```
 "random" - Imputation by Random Sample
```{r}
na_seadec(Serie_2,algorithm = 'random')[29] #Primer dato imputado
na_seadec(Serie_2,algorithm = 'random')[38] #Segundo dato imputado
na_seadec(Serie_2,algorithm = 'random')[39] #Tercer dato imputado
na_seadec_random=na_seadec(Serie_2,algorithm = 'random')[29]-Original[1]
na_seadec_random[2:3]=na_seadec(Serie_2,algorithm = 'random')[38:39]-Original[2:3]
Comparaciones['na_seadec_random']=na_seadec_random
```
 "kalman" - Imputation by Kalman Smoothing and State Space Models
```{r}
na_seadec(Serie_2,algorithm = 'kalman')[29] #Primer dato imputado
na_seadec(Serie_2,algorithm = 'kalman')[38] #Segundo dato imputado
na_seadec(Serie_2,algorithm = 'kalman')[39] #Tercer dato imputado
na_seadec_kalman=na_seadec(Serie_2,algorithm = 'kalman')[29]-Original[1]
na_seadec_kalman[2:3]=na_seadec(Serie_2,algorithm = 'kalman')[38:39]-Original[2:3]
Comparaciones['na_seadec_kalman']=na_seadec_kalman
```
 "ma" - Imputation by Weighted Moving Average
```{r}
na_seadec(Serie_2,algorithm = 'ma')[29] #Primer dato imputado
na_seadec(Serie_2,algorithm = 'ma')[38] #Segundo dato imputado
na_seadec(Serie_2,algorithm = 'ma')[39] #Tercer dato imputado
na_seadec_ma=na_seadec(Serie_2,algorithm = 'ma')[29]-Original[1]
na_seadec_ma[2:3]=na_seadec(Serie_2,algorithm = 'ma')[38:39]-Original[2:3]
Comparaciones['na_seadec_ma']=na_seadec_ma
```

 na\_seasplit:

Seasonally Splitted Missing Value Imputation. Admite los siguiente métodos:

 "interpolation" - Imputation by Interpolation (default choice)
```{r}
na_seasplit(Serie_2,algorithm = 'interpolation')[29] #Primer dato imputado
na_seasplit(Serie_2,algorithm = 'interpolation')[38] #Segundo dato imputado
na_seasplit(Serie_2,algorithm = 'interpolation')[39] #Tercer dato imputado
na_seasplit_interpolation=na_seasplit(Serie_2,algorithm = 'interpolation')[29]-Original[1]
na_seasplit_interpolation[2:3]=na_seasplit(Serie_2,algorithm = 'interpolation')[38:39]-Original[2:3]
Comparaciones['na_seadec_interpolation']=na_seasplit_interpolation
```

 "locf" - Imputation by Last Observation Carried Forward
```{r}
na_seasplit(Serie_2,algorithm = 'locf')[29] #Primer dato imputado
na_seasplit(Serie_2,algorithm = 'locf')[38] #Segundo dato imputado
na_seasplit(Serie_2,algorithm = 'locf')[39] #Tercer dato imputado
na_seadec_locf=na_seasplit(Serie_2,algorithm = 'locf')[29]-Original[1]
na_seadec_locf[2:3]=na_seasplit(Serie_2,algorithm = 'locf')[38:39]-Original[2:3]
Comparaciones['na_seadec_locf']=na_seadec_locf
```
 "mean" - Imputation by Mean Value
```{r}
na_seasplit(Serie_2,algorithm = 'mean')[29] #Primer dato imputado
na_seasplit(Serie_2,algorithm = 'mean')[38] #Segundo dato imputado
na_seasplit(Serie_2,algorithm = 'mean')[39] #Tercer dato imputado
na_seadec_mean=na_seasplit(Serie_2,algorithm = 'mean')[29]-Original[1]
na_seadec_mean[2:3]=na_seasplit(Serie_2,algorithm = 'mean')[38:39]-Original[2:3]
Comparaciones['na_seadec_mean']=na_seadec_mean
```
 "random" - Imputation by Random Sample
```{r}
na_seasplit(Serie_2,algorithm = 'random')[29] #Primer dato imputado
na_seasplit(Serie_2,algorithm = 'random')[38] #Segundo dato imputado
na_seasplit(Serie_2,algorithm = 'random')[39] #Tercer dato imputado
na_seadec_random=na_seasplit(Serie_2,algorithm = 'random')[29]-Original[1]
na_seadec_random[2:3]=na_seasplit(Serie_2,algorithm = 'random')[38:39]-Original[2:3]
Comparaciones['na_seadec_random']=na_seadec_random
```
 "kalman" - Imputation by Kalman Smoothing and State Space Models
```{r}
na_seasplit(Serie_2,algorithm = 'kalman')[29] #Primer dato imputado
na_seasplit(Serie_2,algorithm = 'kalman')[38] #Segundo dato imputado
na_seasplit(Serie_2,algorithm = 'kalman')[39] #Tercer dato imputado
na_seadec_kalman=na_seasplit(Serie_2,algorithm = 'kalman')[29]-Original[1]
na_seadec_kalman[2:3]=na_seasplit(Serie_2,algorithm = 'kalman')[38:39]-Original[2:3]
Comparaciones['na_seadec_kalman']=na_seadec_kalman
```
 "ma" - Imputation by Weighted Moving Average
```{r}
na_seasplit(Serie_2,algorithm = 'ma')[29] #Primer dato imputado
na_seasplit(Serie_2,algorithm = 'ma')[38] #Segundo dato imputado
na_seasplit(Serie_2,algorithm = 'ma')[39] #Tercer dato imputado
na_seadec_ma=na_seasplit(Serie_2,algorithm = 'ma')[29]-Original[1]
na_seadec_ma[2:3]=na_seasplit(Serie_2,algorithm = 'ma')[38:39]-Original[2:3]
Comparaciones['na_seadec_ma']=na_seadec_ma
```

En el dataframe Comparaciones, lo que hacemos es guardar las diferencias
respecto a la observación original, acorde al método respectivo de ajuste.

Veamos cuál es el que minimiza dicho error:
```{r}
Qr1_1971<-Comparaciones[1,]
Qr2_1973<-Comparaciones[2,]
Qr3_1973<-Comparaciones[3,]

#Para el primer trimiestre de 1971
dif_minima_Qr1_1971<-min(abs(Qr1_1971))
dif_minima_Qr1_1971
metodo_minimiza_Qr1_1971<-which.min(abs(Qr1_1971))
metodo_minimiza_Qr1_1971
#Los 5 mejores
aux_indices1<-(sort.list(abs(Qr1_1971)))[1:5]
i=1
for (indice in aux_indices1){
  print(Qr1_1971[indice])
  i=i+1
}
#Para el segundo trimiestre de 1973
dif_minima_Qr2_1973<-min(abs(Qr2_1973))
dif_minima_Qr2_1973
metodo_minimiza_Qr2_1973<-which.min(abs(Qr2_1973))
metodo_minimiza_Qr2_1973
#Los 5 mejores
aux_indices2<-(sort.list(abs(Qr2_1973)))[1:5]
i=1
for (indice in aux_indices2){
  print(Qr2_1973[indice])
  i=i+1
}
#Para el tercer trimiestre de 1973
dif_minima_Qr3_1973<-min(abs(Qr3_1973))
dif_minima_Qr3_1973
metodo_minimiza_Qr3_1973<-which.min(abs(Qr3_1973))
metodo_minimiza_Qr3_1973
#Los 5 mejores
aux_indices3<-(sort.list(abs(Qr3_1973)))[1:5]
i=1
for (indice in aux_indices3){
  print(Qr3_1973[indice])
  i=i+1
}
```

En promedio, el método de kalman con el modelo StructTS y el de Kalman con el auto.arima
logran tener las mejores estimaciones al aparecer siempre entre los 5 primeros
y casi juntos en los 3 casos, por lo que podríamos decir que estas son las dos mejores
opciones para imputar datos, en nuestro caso. Ambas son con el método de Kalman pero
a través de distintos modelos (StructTS y auto.arima)


Aunque de manera individual, para el trimestre 1 de 1971; el mejor es el seadec
usando la media. Para el segundo trimestre de 1973 es el seadec por medias móviles ponderadas (ma) y para el tercer trimestre de 1972 fue el seadec por interpolación. Los 3 coinciden en 
que usan el Seasonally Decomposed Value Imputation, pero hacen la imputación a 
través de distintos métodos (media, medias móviles y medias móviles ponderadas (ma) )

# 3. Ajuste

Con los datos observados completos, ajuste un modelo ARIMA o SARIMA adecuado.

Obtenga correlogramas, revise si los parámetros son significativos, compruebe los supuestos
(que los residuales sean ruido blanco con distribución normal).
Obtenga dos o más posibles modelos, realice análisis de residuales y calcule medidas de
bondad de ajuste. Haga la comparación para decidir cuál modelo sería el más adecuado.


## Estacionariedad

En la primera parte vimos que si le aplicamos la transformación raíz cuadrada
a la serie original, pasa la prueba para varianza constnte:
```{r}
bptest(Serie_sq~tiempo)
```

Ahora, las pruebas para estacionariedad:
```{r}
adf.test(Serie_sq)
kpss.test(Serie_sq)
```
No las pasa.

Aplicamos una diferencia

```{r}
plot(diff(Serie_sq), col = "plum", lwd = 3, xlab = "Tiempo", ylab = " ",
     main = "Serie homoscedastica con una diferencia" )
adf.test(diff(Serie_sq))
kpss.test(diff(Serie_sq))
```
Se contradicen. Apliquemos otra diferencia
```{r}
plot(diff(diff(Serie_sq)), col = "darkolivegreen2", lwd = 3, xlab = "Tiempo", ylab = " ",
     main = "Serie homoscedastica con dos diferencias" )
adf.test(diff(diff(Serie_sq)))
kpss.test(diff(diff(Serie_sq)))
```
Pasa las dos pruebas si aplicamos dos diferencias; trabajaremos con esa.

## Correlogramas

```{r}
Serie_est<-diff(diff(Serie_sq))
```

Visualizamos ACF y PACF

```{r}
tsdisplay(Serie_est)
```
```{r}
k=length(Serie_est)
banda<-qnorm(0.95)/(sqrt(k))
auxacf=acf(Serie_est,plot = F)#MA(6)
ACF_superior<-sum(auxacf$acf>banda)
ACF_inferior<-sum(auxacf$acf< -banda)
superan_banda_acf<-ACF_superior+ACF_inferior
superan_banda_acf
pauxacf=pacf(Serie_est,plot = F)#AR(6)
PACF_superior<-sum(pauxacf$acf>banda)
PACF_inferior<-sum(pauxacf$acf< -banda)
superan_banda_pacf<-PACF_superior+PACF_inferior
superan_banda_pacf
```
Parece, a simple vista, que puede que tengamos un ARIMA(3,2,16). Sin embargo, no hemos
considerado la parte de los ciclos aún.

Veamos el ARIMA(3,2,16)...
```{r}
ARIMA<-arima(Serie_sq,order=c(3,2,16))
ARIMA
```

Ahora veamos la gráfica
```{r}
ARIMA_ajuste <- (Serie_sq - residuals(ARIMA))
ts.plot(Serie_sq, lwd=3, main="Comparación ", ylab="", xlab="")
points(ARIMA_ajuste, type = "l", col ="orange", lty = 2, lwd=3)
###Y ahora los residuales
plot(ARIMA$residuals, type="p", col="blue", ylim=c(-0.15,0.15), ylab="", xlab="", main="Datos discrepantes", las=1, lwd=3)
abline(h=3*(var(ARIMA$residuals)), col="purple", lwd=3)
abline(h=-3*(var(ARIMA$residuals)), col="purple",lwd=3)
```

Ahora atacaremos el problema con un SARIMA(p,d,q)x(P,D,Q), usando la estrategia
definida en la página 180 de Introduction to Time Series and Forecasting de
Peter Brockwell y Richard Davis.

Por el análisis hecho en la primera parte, sabemos que:
$$s=4$$

Podemos estimar d y D como aquellos que hacen que 
$$Y_t=(1-B)^{d}(1-B^s)^D$$
Sea estacionaria. Probemos con d=0 y D=1
```{r}
plot(diff(Serie_sq,lag=4), col = "darkred", lwd = 3, xlab = "Tiempo", ylab = " ",
     main = "Serie homoscedastica con una diferencia de lag=4" )
adf.test(diff(Serie_sq,lag=4))
kpss.test(diff(Serie_sq,lag=4))
```

¡Las pasa! Entonces:
$$d=0,D=1$$

Trabajaremos con esta serie. Veamos su ACF y PACF

```{r}
Serie_est<-diff(Serie_sq,lag=4)
tsdisplay(Serie_est)
```
¡Se ve mucho mejor que el anterior!

¿Cómo elegimos P y Q?
La metodología seguida nos dice que veamos los lags que son múltiplos del ciclo
(de s=4), y ver aquellos que se ajustan a un ARMA(P,Q). Es decir, en los lags
ks $s=4, k\in\mathbb{N}\setminus\{0\}$

¿Cómo elegimos p y q? Debemos fijarnos en aquellos lags entre 1 y s-1, es decir:
Nos fijaremos en los lags $1,2,3$ y los ajustaremos a un ARMA(p,q)

Veamos el ACF
```{r}
k=length(diff(Serie_sq,lag=4))
banda<-qnorm(0.95)/(sqrt(k))
auxacf=acf(diff(Serie_sq,lag=4),plot = F)#MA(6)
ACF_superior<-sum(auxacf$acf>banda)
ACF_inferior<-sum(auxacf$acf< -banda)
superan_banda_acf<-ACF_superior+ACF_inferior
superan_banda_acf
#Los que superan las bandas del acf son:
which(abs(auxacf$acf) > banda)
```
Por lo que:
$$q=2,Q=1$$

Para el PACF:
```{r}
pauxacf=pacf(diff(Serie_sq,lag=4),plot = F)
PACF_superior<-sum(pauxacf$acf>banda)
PACF_inferior<-sum(pauxacf$acf< -banda)
superan_banda_pacf<-PACF_superior+PACF_inferior
superan_banda_pacf
#Los que superan las bandas del pacf son:
which(abs(pauxacf$acf) > banda)
```
Por lo que:
$$p=2, P=0$$
Entonces tenemos un modelo 

$$SARIMA(2,0,2)\times(0,1,1)_{\left[4\right]}$$
Ajustémoslo:

```{r}
SARIMA<-arima(Serie_sq,order=c(2,0,2),seasonal=list(order=c(0,1,1),period=4), include.mean=F) 
SARIMA
```

```{r}
SARIMA_ajuste <- Serie_sq - residuals(SARIMA)
ts.plot(Serie_sq, lwd=3, main="Comparación ", ylab="", xlab="")
points(SARIMA_ajuste, type = "l", col ="orange", lty = 2, lwd=3)
###Y ahora los residuales
plot(SARIMA$residuals, type="p", col="blue", ylim=c(-.15,.15), ylab="", xlab="", main="Datos discrepantes", las=1, lwd=3)
abline(h=3*(var(SARIMA$residuals)), col="purple", lwd=2)
abline(h=-3*(var(SARIMA$residuals)), col="purple",lwd=2)
```

Comparemos con el que ajusta R:


```{r}
modelo_automatico<-auto.arima((diff(Serie_sq,lag=4)))
modelo_automatico
```
Probemos con otra diferencia:
```{r}
adf.test(diff(diff(Serie_sq,lag=4)))
kpss.test((diff(diff(Serie_sq,lag=4))))
tsdisplay(diff(diff(Serie_sq,lag=4)))
```
Sí pasa la prueba; ahora intentemos ajustar con dichas diferencias

```{r}
modelo_automatico<-auto.arima((diff(diff(Serie_sq,lag=4))))
modelo_automatico
```

Entonces es un SARIMA(1,1,0)x(0,1,1)[4]

```{r}
modelo_automatico<-arima(Serie_sq,order=c(1,1,0),seasonal=list(order=c(0,1,1),period=4))
modelo_automatico
```

```{r}
AUTOMATICO_ajuste <- Serie_sq - residuals(modelo_automatico)
ts.plot(Serie_sq, lwd=3, main="Comparación ", ylab="", xlab="")
points(AUTOMATICO_ajuste, type = "l", col ="orange", lty = 2, lwd=3)
###Y ahora los residuales
plot(modelo_automatico$residuals, type="p", col="blue", ylim=c(-.15,.15), ylab="", xlab="", main="Datos discrepantes", las=1, lwd=3)
abline(h=3*(var(modelo_automatico$residuals)), col="purple", lwd=2)
abline(h=-3*(var(modelo_automatico$residuals)), col="purple",lwd=2)
```

Tratemos de ajustar otro SARIMA manualmente; con el enfoque antes mencionado:

Veamos el ACF
```{r}
k=length(diff(diff(Serie_sq,lag=4)))
banda<-qnorm(0.95)/(sqrt(k))
auxacf=acf(diff(diff(Serie_sq,lag=4)),plot = F)#MA(6)
ACF_superior<-sum(auxacf$acf>banda)
ACF_inferior<-sum(auxacf$acf< -banda)
superan_banda_acf<-ACF_superior+ACF_inferior
superan_banda_acf
#Los que superan las bandas del acf son:
which(abs(auxacf$acf) > banda)
```
Por lo que:
$$q=1,Q=2$$

Para el PACF:
```{r}
pauxacf=pacf(diff(diff(Serie_sq,lag=4)),plot = F)
PACF_superior<-sum(pauxacf$acf>banda)
PACF_inferior<-sum(pauxacf$acf< -banda)
superan_banda_pacf<-PACF_superior+PACF_inferior
superan_banda_pacf
#Los que superan las bandas del pacf son:
which(abs(pauxacf$acf) > banda)
```
Por lo que:
$$p=1, P=3$$
Entonces tenemos un modelo 

$$SARIMA(1,1,1)\times(3,1,2)_{\left[4\right]}$$
Ajustémoslo:

```{r}
SARIMA2<-arima(Serie_sq,order=c(1,1,1),seasonal=list(order=c(3,1,2),period=4), include.mean=F) 
SARIMA2
```

```{r}
SARIMA_ajuste2 <- Serie_sq - residuals(SARIMA2)
ts.plot(Serie_sq, lwd=3, main="Comparación ", ylab="", xlab="")
points(SARIMA_ajuste2, type = "l", col ="orange", lty = 2, lwd=3)
###Y ahora los residuales
plot(SARIMA2$residuals, type="p", col="blue", ylim=c(-.15,.15), ylab="", xlab="", main="Datos discrepantes", las=1, lwd=3)
abline(h=3*(var(SARIMA2$residuals)), col="purple", lwd=2)
abline(h=-3*(var(SARIMA2$residuals)), col="purple",lwd=2)
```

Por el AIC y BIC
```{r}
AIC<-c(SARIMA$aic,ARIMA$aic,modelo_automatico$aic, SARIMA2$aic)
BIC<-c(BIC(SARIMA),BIC(ARIMA),BIC(modelo_automatico), BIC(SARIMA2))
loglik<-c(SARIMA$loglik,ARIMA$loglik,modelo_automatico$loglik, SARIMA2$loglik)
Comparar<-data.frame('AIC'=AIC,'BIC'=BIC,'Loglik'=loglik,row.names = c('SARIMA','ARIMA','Automatico', 'SARIMA2'))
Comparar
```
Comparemos los errores:
```{r}
comparar_=cbind("ARIMA",ARIMA$aic,BIC(ARIMA), mean(ARIMA$residuals),
                mean(abs(ARIMA$residuals)),sqrt(mean((ARIMA$residuals)^2)),
                length(ARIMA$coef))

comparar_2=cbind("SARIMA",SARIMA$aic,BIC(SARIMA), mean(SARIMA$residuals),
                 mean(abs(SARIMA$residuals)),sqrt(mean((SARIMA$residuals)^2)),
                 length(SARIMA$coef))

comparar_3=cbind("SARIMA AUTOMÁTICO",modelo_automatico$aic,BIC(modelo_automatico), mean(modelo_automatico$residuals),
                 mean(abs(modelo_automatico$residuals)),sqrt(mean((modelo_automatico$residuals)^2)),
                 length(modelo_automatico$coef))
comparar_4=cbind("SARIMA2",SARIMA2$aic,BIC(SARIMA2), mean(SARIMA2$residuals),
                 mean(abs(SARIMA2$residuals)),sqrt(mean((SARIMA2$residuals)^2)),
                 length(SARIMA2$coef))
nombres=cbind("AJUSTE", "AIC", "BIC","ME","MAE", "RMSE","#Paramatros")

resultados<-rbind(comparar_,comparar_2,comparar_3, comparar_4)
resultados<-as.table(resultados)
colnames(resultados)=c("AJUSTE", "AIC", "BIC","ME","MAE", "RMSE","#Parametros")
rownames(resultados)=c("","", "","")

(resultados)
```
Parece que el SARIMA ajustado de manera automática es quien mejores indicadores tiene,
después sería el segundo SARIMA que ajustamos nosotros, después el primer 
SARIMA y finalmente, el ARIMA


Hagamos la comprobación de supuestos:

## Normalidad

### ARIMA
```{r}
#ARIMA
qqnorm(ARIMA$residuals)
qqline(ARIMA$residuals, col="red", lwd=2)
#Prueba Anderson-Darling
ad.test(ARIMA$residuals)
#Prueba de Shapiro
shapiro.test(ARIMA$residuals)
#Jarque-Bera Test
jarque.bera.test(ARIMA$residuals)
```
Solo pasa Jarque-Bera

### SARIMA
```{r}
#SARIMA
qqnorm(SARIMA$residuals)
qqline(SARIMA$residuals, col="lightslateblue", lwd=2)
#Prueba Anderson-Darling
ad.test(SARIMA$residuals)
#Prueba de Shapiro
shapiro.test(SARIMA$residuals)
#Jarque-Bera Test. tseries
jarque.bera.test(SARIMA$residuals)
```
Solo pasa Anderson-Darling

Apenas pasamos Anderson-Darling
### SARIMA AUTOMÁTICO
```{r}
#SARIMA AUTOMÁTICO
qqnorm(modelo_automatico$residuals)
qqline(modelo_automatico$residuals, col="palevioletred1", lwd=2)
#Prueba Anderson-Darling
ad.test(modelo_automatico$residuals)
#Prueba de Shapiro
shapiro.test(modelo_automatico$residuals)
#Jarque-Bera Test. tseries
jarque.bera.test(modelo_automatico$residuals)
```
Pasa Anderson-Darling con un p-value no tan cerca de 00.05, pero las demás
pruebas las rechaza

### SARIMA2
```{r}
#SARIMA2
qqnorm(SARIMA2$residuals)
qqline(SARIMA2$residuals, col="mediumseagreen", lwd=2)
#Prueba Anderson-Darling
ad.test(SARIMA2$residuals)
#Prueba de Shapiro
shapiro.test(SARIMA2$residuals)
#Jarque-Bera Test. tseries
jarque.bera.test(SARIMA2$residuals)
```
No pasa ningún test.

El modelo ajustado por auto.arima tiene el mejor ajuste acorde a las pruebas

## Varianza constante

### ARIMA
```{r}
#ARIMA
Y <- as.numeric(ARIMA$residuals)
X <- 1:length(ARIMA$residuals)
bptest(Y ~ X)
```
Lo pasa 

### SARIMA
```{r}
#SARIMA
Y <- as.numeric(SARIMA$residuals)
X <- 1:length(SARIMA$residuals)
bptest(Y ~ X)
```
Lo pasa

### SARIMA AUTOMÁTICO
```{r}
#SARIMA AUTOMÁTICO
Y <- as.numeric(modelo_automatico$residuals)
X <- 1:length(modelo_automatico$residuals)
bptest(Y ~ X)
```
Lo pasa

### SARIMA2
```{r}
#SARIMA2
Y <- as.numeric(SARIMA2$residuals)
X <- 1:length(SARIMA2$residuals)
bptest(Y ~ X)
```
Lo pasa

Todos pasan las pruebas; el mayor p-value lo obtuvo el ARIMA

## Media cero 

### ARIMA
```{r}
t.test(ARIMA$residuals,mu=0)
```
Lo pasa

### SARIMA
```{r}
t.test(SARIMA$residuals,mu=0)
```
Lo pasa

### SARIMA  AUTOMÁTICO
```{r}
t.test(modelo_automatico$residuals,mu=0)
```
Lo pasa 

### SARIMA2
```{r}
t.test(SARIMA2$residuals,mu=0)
```
Lo pasa

Todos pasan esta prueba

## Residuales no correlacionados

### ARIMA
```{r}
checkresiduals(ARIMA$residuals)
ggtsdisplay(ARIMA$residuals,main="Residuales")
#No se sale en ningún lag

#Box-Pierce test contrasta
# Ho: Independencia vs. H1: Dependencia
Box.test(ARIMA$residuals, lag =10) #
#Por lo que no están relacionados de manera conjunta

#De manera conjunta, con la prueba de Ljung y Box
#H0:No estan correlacionados de manera conjunta 
# vs 
#H1:Estan correlacionados de manera conjunta
tsdiag(ARIMA)
```
Pasa las pruebas


### SARIMA

```{r}
checkresiduals(SARIMA$residuals)
ggtsdisplay(SARIMA$residuals,main="Residuales")
#Se sale en un lag cerca de 8, por poco.
#Box-Pierce test contrasta
# Ho: Independencia vs. H1: Dependencia
Box.test(SARIMA$residuals, lag =10) 

#De manera conjunta, con la prueba de Ljung y Box
#H0:No estan correlacionados de manera conjunta 
# vs 
#H1:Estan correlacionados de manera conjunta
tsdiag(SARIMA)
```
Pasa las pruebas


### SARIMA AUTOMÁTICO

```{r}
checkresiduals(modelo_automatico$residuals)
ggtsdisplay(modelo_automatico$residuals,main="Residuales")
#Se sale cerca del lag 5
#Box-Pierce test contrasta
# Ho: Independencia vs. H1: Dependencia
Box.test(modelo_automatico$residuals, lag =10) 
#De manera conjunta, con la prueba de Ljung y Box
#H0:No estan correlacionados de manera conjunta 
# vs 
#H1:Estan correlacionados de manera conjunta
tsdiag(modelo_automatico)
```
Pasa las pruebas

### SARIMA2

```{r}
checkresiduals(SARIMA2$residuals)
ggtsdisplay(SARIMA2$residuals,main="Residuales")
#Se sale en el lag 5;
#Box-Pierce test contrasta
# Ho: Independencia vs. H1: Dependencia
Box.test(SARIMA2$residuals, lag =10) 

#De manera conjunta, con la prueba de Ljung y Box
#H0:No estan correlacionados de manera conjunta 
# vs 
#H1:Estan correlacionados de manera conjunta
tsdiag(SARIMA2)
```
Pasa los test


## Significancia de los coeficientes

### ARIMA
```{r}
ARIMA_int<-confint(ARIMA)
ARIMA_int
k=length(confint(ARIMA))/2
no_sign<-c()
for(i in 1:k){
  no_sign[i]<-(ARIMA_int[i]<0 & ARIMA_int[i+k]>0)
}
#No significativos
sum(no_sign)
#Porcentaje no significativos
sum(no_sign)/k
```

### SARIMA
```{r}
SARIMA_int<-confint(SARIMA)
SARIMA_int
k=length(confint(SARIMA))/2
no_sign<-c()
for(i in 1:k){
  no_sign[i]<-(SARIMA_int[i]<0 & SARIMA_int[i+k]>0)
}
#No significativos
sum(no_sign)
#Porcentaje no significativos
sum(no_sign)/k
```

### SARIMA AUTOMÁTICO
```{r}
SARIMA_DRIFT_int<-confint(modelo_automatico)
SARIMA_DRIFT_int
k=length(confint(modelo_automatico))/2
no_sign<-c()
for(i in 1:k){
  no_sign[i]<-(SARIMA_DRIFT_int[i]<0 & SARIMA_DRIFT_int[i+k]>0)
}
#No significativos
sum(no_sign)
#Porcentaje no significativos
sum(no_sign)/k
```

### SARIMA2
```{r}
SARIMA2_int<-confint(SARIMA2)
SARIMA2_int
k=length(confint(SARIMA2))/2
no_sign<-c()
for(i in 1:k){
  no_sign[i]<-(SARIMA2_int[i]<0 & SARIMA2_int[i+k]>0)
}
#No significativos
sum(no_sign)
#Porcentaje no significativos
sum(no_sign)/k
```

Por la simplicidad del modelo (Al tener solo 2 coeficientes), ser el que posee el menor 
porcentaje de coeficientes no significativos y  además, pasar todos los tests (En 
normalidad pasó al menos Anderson-Darling) y tener los mejores índices, el ajustado por
auto.arima parece ser el mejor candidato. Aunque podemos ver otro acercamiento:


```{r}
adf.test(diff(diff(Serie_sq,lag=4),lag=4))
kpss.test(diff(diff(Serie_sq,lag=4),lag=4))
tsdisplay(diff(diff(Serie_sq,lag=4),lag=4))
```
¡Dos diferencias con lag de 4 es estacionario!

Tratemos de ajustar otro SARIMA manualmente; con el enfoque antes mencionado:

Veamos el ACF
```{r}
k=length(diff(diff(Serie_sq,lag=4),lag=4))
banda<-qnorm(0.95)/(sqrt(k))
auxacf=acf(diff(diff(Serie_sq,lag=4),lag=4),plot = F)#MA(6)
ACF_superior<-sum(auxacf$acf>banda)
ACF_inferior<-sum(auxacf$acf< -banda)
superan_banda_acf<-ACF_superior+ACF_inferior
superan_banda_acf
#Los que superan las bandas del acf son:
which(abs(auxacf$acf) > banda)
```
Por lo que:
$$q=2,Q=2$$

Para el PACF:
```{r}
pauxacf=pacf(diff(diff(Serie_sq,lag=4),lag=4),plot = F)
PACF_superior<-sum(pauxacf$acf>banda)
PACF_inferior<-sum(pauxacf$acf< -banda)
superan_banda_pacf<-PACF_superior+PACF_inferior
superan_banda_pacf
#Los que superan las bandas del pacf son:
which(abs(pauxacf$acf) > banda)
```
Por lo que:
$$p=3, P=0$$

Aunque, en el ACF y PACF del SARIMA(1,1,1)x(3,1,2)[4], en el lag=4 en el ACF parece que es por
muy poco que pasa la banda, y en el lag=12 en el PACF se queda un poco por debajo de
la banda, así que trataremos de reducir en un grado P y Q en dicho modelo para ver si 
de esa manera mejorra un poco el ajuste; haciendo un modelo SARIMA(1,1,1)x(2,1,1)[4]

```{r}
modelo_automatico2<-arima(Serie_sq,order=c(3,0,2),seasonal=list(order=c(0,2,2),period=4))
modelo_automatico2
```

### Gráfica 

```{r}
AUTOMATICO2_ajuste <- Serie_sq - residuals(modelo_automatico2)
ts.plot(Serie_sq, lwd=3, main="Comparación ", ylab="", xlab="")
points(AUTOMATICO2_ajuste, type = "l", col ="orange", lty = 2, lwd=3)
###Y ahora los residuales
plot(modelo_automatico2$residuals, type="p", col="blue", ylim=c(-.15,.15), ylab="", xlab="", main="Datos discrepantes", las=1, lwd=3)
abline(h=3*(var(modelo_automatico2$residuals)), col="purple", lwd=2)
abline(h=-3*(var(modelo_automatico2$residuals)), col="purple",lwd=2)
```

### Normalidad

```{r}
#SARIMA AUTOMÁTICO
qqnorm(modelo_automatico2$residuals)
qqline(modelo_automatico2$residuals, col="royalblue2", lwd=2)
#Prueba Anderson-Darling
ad.test(modelo_automatico2$residuals)
#Prueba de Shapiro
shapiro.test(modelo_automatico2$residuals)
#Jarque-Bera Test. tseries
jarque.bera.test(modelo_automatico2$residuals)
```

### Varianza constante

```{r}
#SARIMA AUTOMÁTICO
Y <- as.numeric(modelo_automatico2$residuals)
X <- 1:length(modelo_automatico2$residuals)
bptest(Y ~ X)
```

### Media 0 

```{r}
t.test(modelo_automatico2$residuals,mu=0)
```

### Residuales no correlacionados

```{r}
checkresiduals(modelo_automatico2$residuals)
ggtsdisplay(modelo_automatico2$residuals,main="Residuales")
#Se sale cerca del lag 5
#Box-Pierce test contrasta
# Ho: Independencia vs. H1: Dependencia
Box.test(modelo_automatico2$residuals, lag =10) 
#De manera conjunta, con la prueba de Ljung y Box
#H0:No estan correlacionados de manera conjunta 
# vs 
#H1:Estan correlacionados de manera conjunta
tsdiag(modelo_automatico2)
```

### Coeficiente Significativo

```{r}
SARIMA_DRIFT_int<-confint(modelo_automatico2)
SARIMA_DRIFT_int
k=length(confint(modelo_automatico2))/2
no_sign<-c()
for(i in 1:k){
  no_sign[i]<-(SARIMA_DRIFT_int[i]<0 & SARIMA_DRIFT_int[i+k]>0)
}
#No significativos
sum(no_sign)
#Porcentaje no significativos
sum(no_sign)/k
```

¡Pasa todos los tests de buena manera! Pero... Tenemos problemas en la significancia
de los parámetros.

Tratemos de modificar un poco: Dado que en el PACF, en el lag=3, tenemos (de manera
gráfica), que se queda debajo de la banda de confianza (aunque las consideramos 
en el test que hicimos para ver si superaban o no las bandas), disminuimos $p$ de $3$ 
a $2$ y ajustamos:

```{r}
modelo_automatico2<-arima(Serie_sq,order=c(2,0,2),seasonal=list(order=c(0,2,2),period=4))
modelo_automatico2
```

### Gráfica 

```{r}
AUTOMATICO2_ajuste <- Serie_sq - residuals(modelo_automatico2)
ts.plot(Serie_sq, lwd=3, main="Comparación ", ylab="", xlab="")
points(AUTOMATICO2_ajuste, type = "l", col ="orange", lty = 2, lwd=3)
###Y ahora los residuales
plot(modelo_automatico2$residuals, type="p", col="blue", ylim=c(-.15,.15), ylab="", xlab="", main="Datos discrepantes", las=1, lwd=3)
abline(h=3*(var(modelo_automatico2$residuals)), col="purple", lwd=2)
abline(h=-3*(var(modelo_automatico2$residuals)), col="purple",lwd=2)
```

### Normalidad

```{r}
#SARIMA AUTOMÁTICO
qqnorm(modelo_automatico2$residuals)
qqline(modelo_automatico2$residuals, col="tan3", lwd=2)
#Prueba Anderson-Darling
ad.test(modelo_automatico2$residuals)
#Prueba de Shapiro
shapiro.test(modelo_automatico2$residuals)
#Jarque-Bera Test. tseries
jarque.bera.test(modelo_automatico2$residuals)
```

### Varianza constante

```{r}
#SARIMA AUTOMÁTICO
Y <- as.numeric(modelo_automatico2$residuals)
X <- 1:length(modelo_automatico2$residuals)
bptest(Y ~ X)
```

### Media 0 

```{r}
t.test(modelo_automatico2$residuals,mu=0)
```

### Residuales no correlacionados

```{r}
checkresiduals(modelo_automatico2$residuals)
ggtsdisplay(modelo_automatico2$residuals,main="Residuales")
#Se sale cerca del lag 5
#Box-Pierce test contrasta
# Ho: Independencia vs. H1: Dependencia
Box.test(modelo_automatico2$residuals, lag =10) 
#De manera conjunta, con la prueba de Ljung y Box
#H0:No estan correlacionados de manera conjunta 
# vs 
#H1:Estan correlacionados de manera conjunta
tsdiag(modelo_automatico2)
```

### Coeficiente Significativo

```{r}
SARIMA_DRIFT_int<-confint(modelo_automatico2)
SARIMA_DRIFT_int
k=length(confint(modelo_automatico2))/2
no_sign<-c()
for(i in 1:k){
  no_sign[i]<-(SARIMA_DRIFT_int[i]<0 & SARIMA_DRIFT_int[i+k]>0)
}
#No significativos
sum(no_sign)
#Porcentaje no significativos
sum(no_sign)/k
```
¡Solo uno de los parámetros no es significativo!

¿Y si disminuimos $Q$ en una unidad, dado que en el ACF, en en lag=4 se ve (gráficamente)
que está muy pegado a la banda? Veamos:

```{r}
modelo_automatico3<-arima(Serie_sq,order=c(2,0,2),seasonal=list(order=c(0,2,1),period=4))
modelo_automatico3
```

### Gráfica 

```{r}
AUTOMATICO3_ajuste <- Serie_sq - residuals(modelo_automatico3)
ts.plot(Serie_sq, lwd=3, main="Comparación ", ylab="", xlab="")
points(AUTOMATICO3_ajuste, type = "l", col ="orange", lty = 2, lwd=3)
###Y ahora los residuales
plot(modelo_automatico3$residuals, type="p", col="blue", ylim=c(-.15,.15), ylab="", xlab="", main="Datos discrepantes", las=1, lwd=3)
abline(h=3*(var(modelo_automatico3$residuals)), col="purple", lwd=2)
abline(h=-3*(var(modelo_automatico3$residuals)), col="purple",lwd=2)
```

### Normalidad

```{r}
#SARIMA AUTOMÁTICO
qqnorm(modelo_automatico3$residuals)
qqline(modelo_automatico3$residuals, col="yellow2", lwd=2)
#Prueba Anderson-Darling
ad.test(modelo_automatico3$residuals)
#Prueba de Shapiro
shapiro.test(modelo_automatico3$residuals)
#Jarque-Bera Test. tseries
jarque.bera.test(modelo_automatico3$residuals)
```

### Varianza constante

```{r}
#SARIMA AUTOMÁTICO
Y <- as.numeric(modelo_automatico3$residuals)
X <- 1:length(modelo_automatico3$residuals)
bptest(Y ~ X)
```

### Media 0 

```{r}
t.test(modelo_automatico3$residuals,mu=0)
```

### Residuales no correlacionados

```{r}
checkresiduals(modelo_automatico3$residuals)
ggtsdisplay(modelo_automatico3$residuals,main="Residuales")
#Se sale cerca del lag 5
#Box-Pierce test contrasta
# Ho: Independencia vs. H1: Dependencia
Box.test(modelo_automatico3$residuals, lag =10) 
#De manera conjunta, con la prueba de Ljung y Box
#H0:No estan correlacionados de manera conjunta 
# vs 
#H1:Estan correlacionados de manera conjunta
tsdiag(modelo_automatico3)
```

### Coeficiente Significativo

```{r}
SARIMA_DRIFT_int<-confint(modelo_automatico3)
SARIMA_DRIFT_int
k=length(confint(modelo_automatico3))/2
no_sign<-c()
for(i in 1:k){
  no_sign[i]<-(SARIMA_DRIFT_int[i]<0 & SARIMA_DRIFT_int[i+k]>0)
}
#No significativos
sum(no_sign)
#Porcentaje no significativos
sum(no_sign)/k
```

Esto empeoró los resultados... Nos quedamos con el ajuste anterior

Solo queda ver los indicadores:

```{r}
AIC<-c(SARIMA$aic,ARIMA$aic,modelo_automatico$aic, SARIMA2$aic, modelo_automatico2$aic)
BIC<-c(BIC(SARIMA),BIC(ARIMA),BIC(modelo_automatico), BIC(SARIMA2), BIC(modelo_automatico2))
loglik<-c(SARIMA$loglik,ARIMA$loglik,modelo_automatico$loglik, SARIMA2$loglik, modelo_automatico2$loglik)
Comparar<-data.frame('AIC'=AIC,'BIC'=BIC,'Loglik'=loglik,row.names = c('SARIMA','ARIMA','Automatico', 'SARIMA2','Automático 2'))
Comparar
```
Tiene el mayor AIC y menor LogLik, pero no tiene el mayor BIC.

Comparemos los errores:

```{r}
comparar_=cbind("ARIMA",ARIMA$aic,BIC(ARIMA), mean(ARIMA$residuals),
                mean(abs(ARIMA$residuals)),sqrt(mean((ARIMA$residuals)^2)),
                length(ARIMA$coef))

comparar_2=cbind("SARIMA",SARIMA$aic,BIC(SARIMA), mean(SARIMA$residuals),
                 mean(abs(SARIMA$residuals)),sqrt(mean((SARIMA$residuals)^2)),
                 length(SARIMA$coef))

comparar_3=cbind("SARIMA AUTOMÁTICO",modelo_automatico$aic,BIC(modelo_automatico), 
                 mean(modelo_automatico$residuals),
                 mean(abs(modelo_automatico$residuals)),sqrt(mean((modelo_automatico$residuals)^2)),
                 length(modelo_automatico$coef))
comparar_4=cbind("SARIMA2",SARIMA2$aic,BIC(SARIMA2), mean(SARIMA2$residuals),
                 mean(abs(SARIMA2$residuals)),sqrt(mean((SARIMA2$residuals)^2)),
                 length(SARIMA2$coef))
comparar_5=cbind("SARIMA AUTOMÁTICO2",modelo_automatico2$aic,BIC(modelo_automatico2), 
                 mean(modelo_automatico2$residuals),
                 mean(abs(modelo_automatico2$residuals)),sqrt(mean((modelo_automatico2$residuals)^2)),
                 length(modelo_automatico2$coef))
nombres=cbind("AJUSTE", "AIC", "BIC","ME","MAE", "RMSE","#Paramatros")

resultados<-rbind(comparar_,comparar_2,comparar_3, comparar_4, comparar_5)
resultados<-as.table(resultados)
colnames(resultados)=c("AJUSTE", "AIC", "BIC","ME","MAE", "RMSE","#Parametros")
rownames(resultados)=c("","", "","","")

(resultados)
```

Tiene menos parámetros que el promedio, su ME es menor al promedio en valor absoluto,
así como el menor MAE y RMSE. Su AIC no es el mejor, ni su BIC, pero aunado a que es 
el que mayor coeficientes significativos tiene (solo 1 no lo es) y que pasa todos los 
supuestos, elegimos este modelo

$$\therefore \textbf{Elegimos el SARIMA }(2,0,2)\times(0,2,2)_{\left[4\right]}$$

# 4. Forecasting 

Con el modelo estimado, pronostique $n_{new}=$ 8 (2 años) valores futuros (obtenga
intervalos de predicción).

Usando el modelo mencionado anteiormente hacemos los pronosticos con la serie a la que le aplicamos la raíz cuadrada.

```{r}
inicio<-start(Serie_sq)[1]
final<-end(Serie_sq)[1]
SARIMA_forecast <- predict(modelo_automatico2, n.ahead =8)$pred
SARIMA_forecast_se <- predict(modelo_automatico2, n.ahead = 8)$se
lower<-SARIMA_forecast - qnorm(0.975)*SARIMA_forecast_se
upper<-SARIMA_forecast + qnorm(0.975)*SARIMA_forecast_se
ts.plot(Serie_sq, xlim=c(inicio,final+2),ylim=c(3,7),  main="Prediccion")
points(SARIMA_forecast, type = "l", col = 2)
points(lower, type = "l", col ="blue", lty = 2)
points(upper, type = "l", col ="blue", lty = 2)

par(mfrow=c(2,2))
plot(ARIMA, col="red", main="ARIMA")
plot(SARIMA, col="red", main="SARIMA")
plot(modelo_automatico, main="SARIMA AUTOMÁTICO")
plot(SARIMA2, col="red", main="SARIMA2")

par(mfrow=c(1,1))
```
Entonces, usando la transformación inversa que es elevar al cuadrado, tenemos:
```{r}
Predicciones_raiz<-data.frame('Puntual'=SARIMA_forecast,'Banda_inf'=lower,
                              'Banda_sup'=upper)
Predicciones_raiz
Predicciones_normales<-Predicciones_raiz**2
Predicciones_normales
ts.plot(Serie, xlim=c(inicio[1],final[1]+2.5),ylim=c(9,50),  main="Predicción normal")
points(SARIMA_forecast**2, type = "l", col = 3)
points(lower**2, type = "l", col ="blue", lty = 2)
points(upper**2, type = "l", col ="blue", lty = 2)
```

